import requests
import json
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import time
from urllib.parse import urlencode

class MedicalDataAPI:
    """í•œêµ­ ì§€ì—­ ê³µê³µë°ì´í„° í¬í„¸ ì˜ë£Œê¸°ê´€ ë°ì´í„° API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        self.base_url = "http://www.localdata.go.kr/platform/rest/TO0/openDataApi"
        self.auth_key = "cPf6Cnhiz8tSZsow6jIGOnyndwJnDO2gNz9qLUIYQ90="
        
        # ì˜ë£Œê¸°ê´€ íƒ€ì…ë³„ ì„œë¹„ìŠ¤ ID
        self.service_ids = {
            "ì•½êµ­": "01_01_06_P",
            "ì˜ì›": "01_01_02_P",
            "ë³‘ì›": "01_01_01_P"
        }
        
        # ì˜ë£Œê¸°ê´€ íƒ€ì…ë³„ ì´ëª¨ì§€
        self.emojis = {
            "ì•½êµ­": "ğŸ’Š",
            "ì˜ì›": "ğŸ¥",
            "ë³‘ì›": "ğŸ©"
        }
        
        # ì¶”ì¶œí•  í•„ë“œ ëª©ë¡
        self.required_fields = [
            "mgtNo",       # ê´€ë¦¬ë²ˆí˜¸
            "opnSvcNm",    # ê°œë°©ì„œë¹„ìŠ¤ëª…
            "bplcNm",      # ì‚¬ì—…ì¥ëª…
            "rdnWhlAddr",  # ë„ë¡œëª…ì£¼ì†Œ
            "apvPermYmd",  # ì¸í—ˆê°€ì¼ì
            "uptaeNm",     # ì—…íƒœêµ¬ë¶„ëª…
            "siteTel"      # ì „í™”ë²ˆí˜¸
        ]
    
    def fetch_data_by_date(self, target_date: str, facility_type: str) -> List[Dict]:
        """
        íŠ¹ì • ë‚ ì§œì˜ ì¸í—ˆê°€ì¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ë£Œê¸°ê´€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            target_date: YYYYMMDD í˜•ì‹ì˜ íƒ€ê²Ÿ ë‚ ì§œ
            facility_type: 'ë³‘ì›', 'ì˜ì›', 'ì•½êµ­' ì¤‘ í•˜ë‚˜
            
        Returns:
            í•´ë‹¹ ë‚ ì§œì˜ ì˜ë£Œê¸°ê´€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        if facility_type not in self.service_ids:
            raise ValueError(f"Invalid facility type: {facility_type}. Must be one of {list(self.service_ids.keys())}")
        
        # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (YYYY-MM-DD -> YYYYMMDD)
        if "-" in target_date:
            target_date = target_date.replace("-", "")
        
        all_results = []
        
        # ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ëˆ„ë½ ë°©ì§€
        # 1. ì¸í—ˆê°€ì¼ì ê¸°ì¤€ ê²€ìƒ‰
        print(f"\n[ë””ë²„ê¹…] ì¸í—ˆê°€ì¼ì ê¸°ì¤€ ê²€ìƒ‰ ì‹œì‘: {target_date}")
        results_by_permit = self._fetch_by_permit_date(target_date, facility_type)
        all_results.extend(results_by_permit)
        print(f"[ë””ë²„ê¹…] ì¸í—ˆê°€ì¼ì ê¸°ì¤€ ê²€ìƒ‰ ê²°ê³¼: {len(results_by_permit)}ê°œ")
        
        # 2. ë°ì´í„°ê°±ì‹ ì¼ì ê¸°ì¤€ ê²€ìƒ‰ (ìµœê·¼ 30ì¼ê°„ì˜ ê°±ì‹  ë°ì´í„° ì¤‘ í•´ë‹¹ ì¸í—ˆê°€ì¼ í•„í„°ë§)
        print(f"\n[ë””ë²„ê¹…] ë°ì´í„°ê°±ì‹ ì¼ì ê¸°ì¤€ ê²€ìƒ‰ ì‹œì‘")
        results_by_update = self._fetch_by_update_date(target_date, facility_type)
        all_results.extend(results_by_update)
        print(f"[ë””ë²„ê¹…] ë°ì´í„°ê°±ì‹ ì¼ì ê¸°ì¤€ ê²€ìƒ‰ ê²°ê³¼: {len(results_by_update)}ê°œ")
        
        # ì¤‘ë³µ ì œê±° (ê´€ë¦¬ë²ˆí˜¸ ê¸°ì¤€)
        unique_results = self._remove_duplicates(all_results)
        print(f"[ë””ë²„ê¹…] ì¤‘ë³µ ì œê±° í›„ ìµœì¢… ê²°ê³¼: {len(unique_results)}ê°œ")
        
        return unique_results
    
    def _fetch_by_permit_date(self, target_date: str, facility_type: str) -> List[Dict]:
        """ì¸í—ˆê°€ì¼ì ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ê²€ìƒ‰"""
        # ë” ë„“ì€ ë‚ ì§œ ë²”ìœ„ë¡œ ê²€ìƒ‰ (íƒ€ê²Ÿ ë‚ ì§œ ì „í›„ 7ì¼)
        target_dt = datetime.strptime(target_date, "%Y%m%d")
        today = datetime.now()
        
        # APIê°€ ë¯¸ë˜ ë‚ ì§œë¥¼ ê±°ë¶€í•˜ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„
        start_dt = target_dt - timedelta(days=7)
        end_dt = target_dt + timedelta(days=7)
        
        # ì¢…ë£Œì¼ì´ ì˜¤ëŠ˜ë³´ë‹¤ ë¯¸ë˜ì¸ ê²½ìš° ì˜¤ëŠ˜ë¡œ ì¡°ì •
        if end_dt > today:
            end_dt = today
            print(f"[ë””ë²„ê¹…] ì¢…ë£Œì¼ì„ ì˜¤ëŠ˜({today.strftime('%Y%m%d')})ë¡œ ì¡°ì •")
        
        params = {
            "authKey": self.auth_key,
            "opnSvcId": self.service_ids[facility_type],
            "bgnYmd": start_dt.strftime("%Y%m%d"),
            "endYmd": end_dt.strftime("%Y%m%d"),
            "pageSize": "1000"
        }
        
        print(f"[ë””ë²„ê¹…] ë„“ì€ ë²”ìœ„ ê²€ìƒ‰: {start_dt.strftime('%Y%m%d')} ~ {end_dt.strftime('%Y%m%d')}")
        print(f"[ë””ë²„ê¹…] í˜„ì¬ ì‹œìŠ¤í…œ ë‚ ì§œ: {today.strftime('%Y-%m-%d')}")
        
        return self._fetch_paginated_data(params, target_date)
    
    def _fetch_by_update_date(self, target_date: str, facility_type: str) -> List[Dict]:
        """ë°ì´í„°ê°±ì‹ ì¼ì ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ê²€ìƒ‰"""
        # ë” ë„“ì€ ë²”ìœ„ë¡œ ê²€ìƒ‰í•˜ì—¬ ìµœì‹  ì¸í—ˆê°€ ë°ì´í„° ëˆ„ë½ ë°©ì§€
        target_dt = datetime.strptime(target_date, "%Y%m%d")
        today = datetime.now()
        
        # íƒ€ê²Ÿ ë‚ ì§œë¶€í„° 3ì¼ í›„ê¹Œì§€ ê²€ìƒ‰ (ìµœì‹  ì¸í—ˆê°€ ë°ì´í„°ëŠ” ë³´í†µ ë©°ì¹  í›„ì— ê°±ì‹ ë¨)
        start_dt = target_dt
        end_dt = min(target_dt + timedelta(days=3), today)
        
        # ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ìœ¼ë©´ ê²€ìƒ‰í•˜ì§€ ì•ŠìŒ
        if start_dt > end_dt:
            print(f"[ë””ë²„ê¹…] ë°ì´í„°ê°±ì‹ ì¼ì ê²€ìƒ‰ ë¶ˆê°€: ì‹œì‘ì¼({start_dt.strftime('%Y%m%d')}) > ì¢…ë£Œì¼({end_dt.strftime('%Y%m%d')})")
            return []
        
        params = {
            "authKey": self.auth_key,
            "opnSvcId": self.service_ids[facility_type],
            "lastModTsBgn": start_dt.strftime("%Y%m%d"),
            "lastModTsEnd": end_dt.strftime("%Y%m%d"),
            "pageSize": "1000"
        }
        
        print(f"[ë””ë²„ê¹…] ë°ì´í„°ê°±ì‹ ì¼ì ë²”ìœ„: {start_dt.strftime('%Y%m%d')} ~ {end_dt.strftime('%Y%m%d')}")
        
        return self._fetch_paginated_data(params, target_date)
    
    def _fetch_paginated_data(self, params: Dict, target_date: str) -> List[Dict]:
        """í˜ì´ì§€ë„¤ì´ì…˜ì„ ì²˜ë¦¬í•˜ë©° ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        all_data = []
        page_index = 1
        
        while True:
            params["pageIndex"] = str(page_index)
            
            try:
                # API í˜¸ì¶œ
                print(f"\n[ë””ë²„ê¹…] API í˜¸ì¶œ - í˜ì´ì§€ {page_index}")
                print(f"[ë””ë²„ê¹…] URL: {self.base_url}")
                print(f"[ë””ë²„ê¹…] íŒŒë¼ë¯¸í„°: {params}")
                
                response = requests.get(self.base_url, params=params, timeout=30)
                response.raise_for_status()
                
                # ì‘ë‹µ í˜•ì‹ í™•ì¸
                content_type = response.headers.get('Content-Type', '').lower()
                print(f"[ë””ë²„ê¹…] Content-Type: {content_type}")
                
                # XML ë˜ëŠ” JSON ì‘ë‹µ ì²˜ë¦¬
                data = None
                rows = []
                total_count = 0
                
                if 'xml' in content_type:
                    # XML íŒŒì‹±
                    print(f"[ë””ë²„ê¹…] XML ì‘ë‹µ íŒŒì‹± ì¤‘...")
                    try:
                        root = ET.fromstring(response.text)
                        
                        # XMLì—ì„œ rows ì¶”ì¶œ
                        xml_rows = root.findall('.//row')
                        print(f"[ë””ë²„ê¹…] XMLì—ì„œ {len(xml_rows)}ê°œ row ë°œê²¬")
                        
                        # XML rowë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                        for xml_row in xml_rows:
                            row_dict = {}
                            for child in xml_row:
                                row_dict[child.tag] = child.text if child.text else ""
                            rows.append(row_dict)
                        
                        # ì „ì²´ ê°œìˆ˜ ì¶”ì¶œ (ì²« í˜ì´ì§€ë§Œ)
                        if page_index == 1:
                            total_count_elem = root.find('.//totalCount')
                            if total_count_elem is not None:
                                total_count = int(total_count_elem.text or 0)
                            else:
                                total_count = len(rows)  # fallback
                        
                    except ET.ParseError as pe:
                        print(f"[ë””ë²„ê¹…] XML íŒŒì‹± ì—ëŸ¬: {pe}")
                        break
                else:
                    # JSON íŒŒì‹± (ê¸°ì¡´ ë¡œì§)
                    try:
                        data = response.json()
                        
                        # ì „ì²´ ì‘ë‹µ êµ¬ì¡° í™•ì¸ (ì²« í˜ì´ì§€ë§Œ)
                        if page_index == 1:
                            print(f"\n[ë””ë²„ê¹…] API ì‘ë‹µ êµ¬ì¡°:")
                            print(json.dumps(data, ensure_ascii=False, indent=2)[:2000] + "...")
                        
                        # ì—ëŸ¬ ì²´í¬
                        if "result" in data and "header" in data["result"]:
                            header = data["result"]["header"]
                            if "process" in header and "code" in header["process"]:
                                # codeê°€ "00" ë˜ëŠ” "000"ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì—ëŸ¬ë¡œ ì²˜ë¦¬
                                if header["process"]["code"] not in ["00", "000"]:
                                    print(f"[ë””ë²„ê¹…] API ì—ëŸ¬: {header['process'].get('message', 'Unknown error')}")
                                    break
                    except json.JSONDecodeError as je:
                        print(f"[ë””ë²„ê¹…] JSON íŒŒì‹± ì—ëŸ¬: {je}")
                        break
                
                # JSON ì‘ë‹µì—ì„œ rows ì¶”ì¶œ (dataê°€ ìˆì„ ë•Œë§Œ)
                if data is not None:
                    # ì¼€ì´ìŠ¤ 1: result.body êµ¬ì¡°
                    if "result" in data and "body" in data["result"]:
                        body = data["result"]["body"]
                        
                        # bodyê°€ ë‹¨ì¼ ê°ì²´ì¸ ê²½ìš° ì²˜ë¦¬
                        if isinstance(body, dict):
                            # body ì•ˆì— rows í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                            if "rows" in body:
                                rows_data = body["rows"]
                                # rowsê°€ ë¦¬ìŠ¤íŠ¸ì´ê³  ì²« ë²ˆì§¸ ìš”ì†Œê°€ @class: listì¸ ê²½ìš° ì²˜ë¦¬
                                if isinstance(rows_data, list) and len(rows_data) > 0:
                                    # ì²« ë²ˆì§¸ ìš”ì†Œê°€ ê°ì²´ì´ê³  row í‚¤ë¥¼ ê°€ì§„ ê²½ìš°
                                    if isinstance(rows_data[0], dict) and "row" in rows_data[0]:
                                        # row ì•ˆì˜ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ
                                        rows = rows_data[0]["row"]
                                    elif isinstance(rows_data[0], dict) and rows_data[0].get("@class") == "list":
                                        # ì‹¤ì œ ë°ì´í„°ëŠ” ë‘ ë²ˆì§¸ ìš”ì†Œë¶€í„°
                                        rows = rows_data[1:] if len(rows_data) > 1 else []
                                    else:
                                        rows = rows_data
                                else:
                                    rows = rows_data if isinstance(rows_data, list) else [rows_data]
                            else:
                                # body ìì²´ê°€ ë°ì´í„°ì¸ ê²½ìš°
                                rows = [body]
                        elif isinstance(body, list):
                            rows = body
                    # ì¼€ì´ìŠ¤ 2: body ì§ì ‘ ì ‘ê·¼
                    elif "body" in data:
                        rows = data["body"]
                    # ì¼€ì´ìŠ¤ 3: row ì§ì ‘ ì ‘ê·¼
                    elif "row" in data:
                        rows = data["row"]
                    # ì¼€ì´ìŠ¤ 4: localdata êµ¬ì¡°
                    elif "localdata" in data:
                        rows = data["localdata"]
                    
                    # ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    if not isinstance(rows, list):
                        rows = [rows] if rows else []
                        
                    # í˜ì´ì§• ì •ë³´ í™•ì¸ (JSONì—ì„œ)
                    if "result" in data and "header" in data["result"] and "paging" in data["result"]["header"]:
                        paging = data["result"]["header"]["paging"]
                        total_count = int(paging.get("totalCount", 0))
                    else:
                        total_count = len(rows)
                
                print(f"[ë””ë²„ê¹…] í˜ì´ì§€ {page_index}ì—ì„œ {len(rows)}ê°œ í–‰ ë°œê²¬")
                
                # íƒ€ê²Ÿ ë‚ ì§œì™€ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ë§Œ í•„í„°ë§í•˜ê³  í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œ
                page_data_count = 0
                for row in rows:
                    # rowê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
                    if not isinstance(row, dict):
                        continue
                        
                    # ì¸í—ˆê°€ì¼ì í™•ì¸ (ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬)
                    apv_date = str(row.get("apvPermYmd", ""))
                    if "-" in apv_date:
                        apv_date = apv_date.replace("-", "")
                    
                    # ì²« ëª‡ ê°œ ë°ì´í„°ì˜ apvPermYmd ê°’ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                    if page_index == 1 and len(all_data) < 3:
                        print(f"[ë””ë²„ê¹…] ë°ì´í„° ìƒ˜í”Œ - apvPermYmd: {apv_date}, bplcNm: {row.get('bplcNm', 'N/A')}")
                    
                    if apv_date == target_date:
                        filtered_row = {field: row.get(field, "") for field in self.required_fields}
                        all_data.append(filtered_row)
                        page_data_count += 1
                        
                        # ì²« ë²ˆì§¸ ë§¤ì¹­ ë°ì´í„° ì¶œë ¥
                        if page_data_count == 1:
                            print(f"\n[ë””ë²„ê¹…] ì²« ë²ˆì§¸ ë§¤ì¹­ ë°ì´í„°:")
                            print(json.dumps(filtered_row, ensure_ascii=False, indent=2))
                
                print(f"[ë””ë²„ê¹…] í˜ì´ì§€ {page_index}ì—ì„œ íƒ€ê²Ÿ ë‚ ì§œì™€ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°: {page_data_count}ê°œ")
                print(f"[ë””ë²„ê¹…] ì „ì²´ ë°ì´í„° ìˆ˜: {total_count}")
                
                # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                if len(rows) < int(params["pageSize"]) or (total_count > 0 and page_index * int(params["pageSize"]) >= total_count):
                    break
                
                page_index += 1
                
                # ë„ˆë¬´ ë§ì€ í˜ì´ì§€ ë°©ì§€
                if page_index > 10:
                    print(f"[ë””ë²„ê¹…] ìµœëŒ€ í˜ì´ì§€ ìˆ˜(10) ë„ë‹¬. ê²€ìƒ‰ ì¤‘ë‹¨.")
                    break
                
                # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ (rate limiting ë°©ì§€)
                time.sleep(0.5)
                
            except requests.exceptions.RequestException as e:
                print(f"[ë””ë²„ê¹…] API í˜¸ì¶œ ì—ëŸ¬ (í˜ì´ì§€ {page_index}): {e}")
                break
            except json.JSONDecodeError as e:
                print(f"[ë””ë²„ê¹…] JSON íŒŒì‹± ì—ëŸ¬ (í˜ì´ì§€ {page_index}): {e}")
                print(f"[ë””ë²„ê¹…] ì‘ë‹µ ë‚´ìš©: {response.text[:500]}...")
                break
            except Exception as e:
                print(f"[ë””ë²„ê¹…] ì˜ˆê¸°ì¹˜ ì•Šì€ ì—ëŸ¬ (í˜ì´ì§€ {page_index}): {e}")
                import traceback
                traceback.print_exc()
                break
        
        return all_data
    
    def _remove_duplicates(self, data_list: List[Dict]) -> List[Dict]:
        """ê´€ë¦¬ë²ˆí˜¸(mgtNo) ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°"""
        seen = set()
        unique_data = []
        
        for item in data_list:
            mgt_no = item.get("mgtNo")
            if mgt_no and mgt_no not in seen:
                seen.add(mgt_no)
                unique_data.append(item)
        
        return unique_data
    
    def fetch_all_facilities_by_date(self, target_date: str) -> Dict[str, List[Dict]]:
        """
        íŠ¹ì • ë‚ ì§œì˜ ëª¨ë“  ì˜ë£Œê¸°ê´€ íƒ€ì… ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            target_date: YYYYMMDD ë˜ëŠ” YYYY-MM-DD í˜•ì‹ì˜ íƒ€ê²Ÿ ë‚ ì§œ
            
        Returns:
            {'ë³‘ì›': [...], 'ì˜ì›': [...], 'ì•½êµ­': [...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        """
        results = {}
        
        for facility_type in self.service_ids.keys():
            print(f"\n{'='*60}")
            print(f"{self.emojis[facility_type]} {facility_type} ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            print(f"{'='*60}")
            facility_data = self.fetch_data_by_date(target_date, facility_type)
            results[facility_type] = facility_data
            print(f"\n[ê²°ê³¼] {self.emojis[facility_type]} {facility_type}: {len(facility_data)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        
        return results
    
    def print_summary_report(self, all_data: Dict[str, List[Dict]], target_date: str):
        """ìˆ˜ì§‘ëœ ë°ì´í„°ì˜ ìš”ì•½ ë³´ê³ ì„œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
        print(f"\n{'='*80}")
        print(f"ğŸ“Š ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ë³´ê³ ì„œ")
        print(f"ğŸ—“ï¸  ëŒ€ìƒ ë‚ ì§œ: {target_date}")
        print(f"{'='*80}")
        
        total_count = 0
        for facility_type, data in all_data.items():
            count = len(data)
            total_count += count
            print(f"\n{self.emojis[facility_type]} {facility_type}: {count}ê°œ")
            
            if data and count > 0:
                # ì§€ì—­ë³„ í†µê³„ (ìƒìœ„ 3ê°œ ì§€ì—­)
                regions = {}
                for item in data:
                    addr = item.get('rdnWhlAddr', '')
                    if addr:
                        region = addr.split()[0] if addr else "ê¸°íƒ€"
                        regions[region] = regions.get(region, 0) + 1
                
                if regions:
                    print(f"   ğŸ“ ì£¼ìš” ì§€ì—­:")
                    sorted_regions = sorted(regions.items(), key=lambda x: x[1], reverse=True)[:3]
                    for region, cnt in sorted_regions:
                        print(f"      - {region}: {cnt}ê°œ")
        
        print(f"\n{'='*80}")
        print(f"ğŸ“Š ì´ {total_count}ê°œ ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        print(f"{'='*80}\n")
    
    def save_to_json_with_summary(self, all_data: Dict[str, List[Dict]], target_date: str):
        """ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ìš”ì•½ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤."""
        # ìš”ì•½ ì •ë³´ ìƒì„±
        summary = {
            "collection_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "target_date": target_date,
            "statistics": {}
        }
        
        for facility_type, data in all_data.items():
            summary["statistics"][facility_type] = {
                "emoji": self.emojis[facility_type],
                "count": len(data),
                "data": data
            }
        
        # íŒŒì¼ ì €ì¥
        output_filename = f"medical_data_{target_date.replace('-', '')}.json"
        with open(output_filename, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ë°ì´í„°ê°€ {output_filename} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return output_filename


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    api = MedicalDataAPI()
    
    # í…ŒìŠ¤íŠ¸í•  ë‚ ì§œ
    target_date = "2025-06-20"
    
    print(f"\nğŸ¥ í•œêµ­ ì§€ì—­ ê³µê³µë°ì´í„° ì˜ë£Œê¸°ê´€ ì •ë³´ ìˆ˜ì§‘ê¸° ğŸ¥")
    print(f"{'='*80}")
    print(f"íƒ€ê²Ÿ ë‚ ì§œ: {target_date}")
    print(f"í˜„ì¬ ì‹œìŠ¤í…œ ë‚ ì§œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*80}")
    
    # ëª¨ë“  ì˜ë£Œê¸°ê´€ íƒ€ì… ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    all_data = api.fetch_all_facilities_by_date(target_date)
    
    # ìš”ì•½ ë³´ê³ ì„œ ì¶œë ¥
    api.print_summary_report(all_data, target_date)
    
    # ê° íƒ€ì…ë³„ ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
    print("\nğŸ“‹ ìˆ˜ì§‘ëœ ë°ì´í„° ìƒ˜í”Œ:")
    print("="*80)
    
    for facility_type, data in all_data.items():
        if data:
            print(f"\n{api.emojis[facility_type]} {facility_type} ìƒ˜í”Œ (ìµœëŒ€ 3ê°œ):")
            for i, item in enumerate(data[:3], 1):
                print(f"\n   [{i}] {item.get('bplcNm', 'N/A')}")
                print(f"       ğŸ“ ì£¼ì†Œ: {item.get('rdnWhlAddr', 'N/A')}")
                print(f"       ğŸ“… ì¸í—ˆê°€ì¼: {item.get('apvPermYmd', 'N/A')}")
                print(f"       ğŸ“ ì „í™”: {item.get('siteTel', 'ì—†ìŒ')}")
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    print("\n" + "="*80)
    filename = api.save_to_json_with_summary(all_data, target_date)
    
    print(f"\nâœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ğŸ’¡ ì €ì¥ëœ íŒŒì¼ì„ í™•ì¸í•˜ì‹œë ¤ë©´: cat {filename}") 
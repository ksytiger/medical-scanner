#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê¸ˆì£¼ì˜ ê°œì›ë³‘ì› ë°ì´í„° ì¶”ì¶œê¸°
Weekly Hospital Opening Data Extractor

ì‚¬ìš©ë²•:
  python fetchLocalData.py                            # í•˜ë“œì½”ë”© ëª¨ë“œ (íŒŒì¼ ìƒë‹¨ì—ì„œ ë‚ ì§œ ì„¤ì •)
  python fetchLocalData.py --week 2025-06-15          # í•´ë‹¹ ì£¼ ì›”ìš”ì¼ë¶€í„° 5ì¼ê°„
  python fetchLocalData.py --current-week             # í˜„ì¬ ì£¼
  python fetchLocalData.py --start-date 2025-06-08 --days 5  # ì§ì ‘ ë‚ ì§œ ì§€ì •
  python fetchLocalData.py --help                     # ë„ì›€ë§

ì‘ì„±ì: AI Assistant
ìµœì¢… ìˆ˜ì •: 2025-01-27
"""

import requests
import xml.etree.ElementTree as ET
import argparse
import json
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional
from tabulate import tabulate

# ============================================================
# ì„¤ì • ë° ìƒìˆ˜
# ============================================================

# ===== í•˜ë“œì½”ë”© ì„¤ì • (ëª…ë ¹í–‰ ì¸ì ì—†ì´ ì‹¤í–‰í•  ë•Œ ì‚¬ìš©) =====
HARDCODED_START_DATE = "20250609"  # ì‹œì‘ ë‚ ì§œ (YYYYMMDD) - ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”!
HARDCODED_END_DATE = "20250615"    # ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD) - ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”!
ENABLE_HARDCODED_MODE = True       # True: í•˜ë“œì½”ë”© ëª¨ë“œ í™œì„±í™”, False: ëª…ë ¹í–‰ ì¸ì í•„ìˆ˜

# API ì„¤ì •
API_URL = "http://www.localdata.go.kr/platform/rest/TO0/openDataApi"
AUTH_KEYS = [
    "k8ClVr9qMtXeZqrlBAgXAraxYweS6wAY4aabuXLwMtA=",  # ê¸°ë³¸ í‚¤
    "89dp30YYjiDahshFV4xPe11tJPooygtb9/z3XtSB2EU="   # ë°±ì—… í‚¤
]
SERVICE_ID = "01_01_01_P"  # ì˜ë£Œê¸°ê´€ ì„œë¹„ìŠ¤ ID

# ê¸°ë³¸ ì„¤ì •
DEFAULT_DAYS = 5  # ê¸°ë³¸ ê¸°ê°„ (5ì¼)
MAX_PAGES_PER_RANGE = 20  # ê° ë‚ ì§œ ë²”ìœ„ë‹¹ ìµœëŒ€ í˜ì´ì§€ ìˆ˜
PAGE_SIZE_BGN_END = 500
PAGE_SIZE_LASTMOD = 300

# ============================================================
# ë‚ ì§œ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ============================================================

def get_week_start_date(date_str: str) -> datetime:
    """ì£¼ì–´ì§„ ë‚ ì§œê°€ í¬í•¨ëœ ì£¼ì˜ ì›”ìš”ì¼ì„ ë°˜í™˜"""
    date = datetime.strptime(date_str, "%Y-%m-%d")
    # ì›”ìš”ì¼ì„ ì£¼ì˜ ì‹œì‘ìœ¼ë¡œ ì„¤ì • (weekday() 0=ì›”ìš”ì¼)
    days_since_monday = date.weekday()
    monday = date - timedelta(days=days_since_monday)
    return monday

def get_current_week_start() -> datetime:
    """í˜„ì¬ ì£¼ì˜ ì›”ìš”ì¼ì„ ë°˜í™˜"""
    today = datetime.now()
    days_since_monday = today.weekday()
    monday = today - timedelta(days=days_since_monday)
    return monday

def format_date_for_api(date: datetime) -> str:
    """datetimeì„ APIìš© ë‚ ì§œ í˜•ì‹(YYYYMMDD)ìœ¼ë¡œ ë³€í™˜"""
    return date.strftime("%Y%m%d")

def format_date_for_display(date: datetime) -> str:
    """datetimeì„ í‘œì‹œìš© ë‚ ì§œ í˜•ì‹(YYYY-MM-DD)ìœ¼ë¡œ ë³€í™˜"""
    return date.strftime("%Y-%m-%d")

def calculate_date_range(start_date: datetime, days: int) -> Tuple[str, str, str, str]:
    """ì‹œì‘ì¼ê³¼ ê¸°ê°„ìœ¼ë¡œë¶€í„° APIìš© ë° í‘œì‹œìš© ë‚ ì§œ ë²”ìœ„ ê³„ì‚°"""
    end_date = start_date + timedelta(days=days)
    
    api_start = format_date_for_api(start_date)
    api_end = format_date_for_api(end_date)
    display_start = format_date_for_display(start_date)
    display_end = format_date_for_display(end_date)
    
    return api_start, api_end, display_start, display_end

# ============================================================
# ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ë“¤
# ============================================================

def fetch_medical_data_comprehensive(api_start: str, api_end: str, use_bgn_end: bool = True) -> List:
    """í¬ê´„ì  ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘"""
    all_data = []
    page_index = 1
    
    method_name = "bgnYmd/endYmd" if use_bgn_end else "lastModTsBgn/lastModTsEnd"
    print(f"\nğŸš€ {method_name} ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    
    # lastModTsBgn/lastModTsEndì˜ ê²½ìš° ì—¬ëŸ¬ ë²”ìœ„ë¥¼ ì‹œë„
    date_ranges = []
    if not use_bgn_end:
        # ëª©í‘œ ë‚ ì§œ ì£¼ë³€ì˜ ì—¬ëŸ¬ ë²”ìœ„ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        start_date = datetime.strptime(api_start, "%Y%m%d")
        
        # ê¸°ë³¸ ë²”ìœ„
        date_ranges.append((api_start, api_end, "ê¸°ë³¸ ë²”ìœ„"))
        
        # ì´ì „ ë²”ìœ„ (1ì£¼ ì „)
        prev_week_start = start_date - timedelta(days=7)
        prev_week_end = start_date - timedelta(days=1)
        date_ranges.append((
            format_date_for_api(prev_week_start),
            format_date_for_api(prev_week_end),
            "ì´ì „ ì£¼ ë²”ìœ„"
        ))
        
        # ì´í›„ ë²”ìœ„ (1ì£¼ í›„)
        next_week_start = start_date + timedelta(days=7)
        next_week_end = start_date + timedelta(days=14)
        date_ranges.append((
            format_date_for_api(next_week_start),
            format_date_for_api(next_week_end),
            "ì´í›„ ì£¼ ë²”ìœ„"
        ))
    
    range_index = 0
    
    while True:
        if use_bgn_end:
            # bgnYmd/endYmd ë°©ì‹
            params = {
                "authKey": AUTH_KEYS[0],
                "opnSvcId": SERVICE_ID,
                "bgnYmd": api_start,
                "endYmd": api_end,
                "pageSize": PAGE_SIZE_BGN_END,
                "pageIndex": page_index
            }
        else:
            # lastModTsBgn/lastModTsEnd ë°©ì‹ - ì—¬ëŸ¬ ë²”ìœ„ ì‹œë„
            if range_index >= len(date_ranges):
                break
                
            start_date, end_date, range_name = date_ranges[range_index]
            print(f"   ğŸ” {range_name} ì‹œë„: {start_date}~{end_date}")
            
            params = {
                "authKey": AUTH_KEYS[0],
                "opnSvcId": SERVICE_ID,
                "lastModTsBgn": start_date,
                "lastModTsEnd": end_date,
                "pageSize": PAGE_SIZE_LASTMOD,
                "pageIndex": page_index
            }
        
        print(f"ğŸ“„ í˜ì´ì§€ {page_index} ìš”ì²­...")
        
        response = requests.get(API_URL, params=params)
        
        if response.status_code != 200:
            print(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            if not use_bgn_end:
                range_index += 1
                page_index = 1
                continue
            else:
                break
            
        try:
            root = ET.fromstring(response.text)
        except ET.ParseError as e:
            print(f"âŒ XML íŒŒì‹± ì‹¤íŒ¨: {e}")
            if not use_bgn_end:
                range_index += 1
                page_index = 1
                continue
            else:
                break
            
        rows = root.findall('.//row')
        print(f"   â†’ {len(rows)}ê°œ ë°ì´í„° ìˆ˜ì§‘")
        
        if len(rows) == 0:
            if not use_bgn_end:
                # í˜„ì¬ ë²”ìœ„ì—ì„œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë‹¤ìŒ ë²”ìœ„ë¡œ
                range_index += 1
                page_index = 1
                continue
            else:
                break
            
        all_data.extend(rows)
        page_index += 1
        
        if len(rows) < (PAGE_SIZE_BGN_END if use_bgn_end else PAGE_SIZE_LASTMOD):
            if not use_bgn_end:
                # í˜„ì¬ ë²”ìœ„ ì™„ë£Œ, ë‹¤ìŒ ë²”ìœ„ë¡œ
                range_index += 1
                page_index = 1
                continue
            else:
                break
            
        if page_index > MAX_PAGES_PER_RANGE:
            if not use_bgn_end:
                print(f"   âš ï¸ {range_name}: {page_index-1}í˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘")
                range_index += 1
                page_index = 1
                continue
            else:
                print(f"âš ï¸ ì•ˆì „ì¥ì¹˜: {page_index-1}í˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘ ì™„ë£Œ")
                break
    
    print(f"âœ… {method_name}: ì´ {len(all_data)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
    return all_data

def filter_by_opening_date(data: List, start_date: str, end_date: str) -> List[Dict]:
    """ê°œì›ì¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° í•„í„°ë§"""
    filtered_facilities = []
    
    for row in data:
        apv_perm_ymd = row.find('apvPermYmd')
        if apv_perm_ymd is not None and apv_perm_ymd.text:
            opening_date = apv_perm_ymd.text.strip()
            
            # ë‚ ì§œ í˜•ì‹ í†µì¼ (í•˜ì´í”ˆ ì œê±°)
            normalized_opening_date = opening_date.replace('-', '')
            
            if start_date <= normalized_opening_date <= end_date:
                facility = extract_facility_info(row)
                facility['ë°ì´í„°ì†ŒìŠ¤'] = ''  # ë‚˜ì¤‘ì— ì„¤ì •ë¨
                filtered_facilities.append(facility)
    
    return filtered_facilities

def extract_facility_info(row) -> Dict:
    """XML í–‰ì—ì„œ ì˜ë£Œê¸°ê´€ ì •ë³´ ì¶”ì¶œ"""
    def get_text(element_name):
        element = row.find(element_name)
        return element.text.strip() if element is not None and element.text else None
    
    return {
        "ì‚¬ì—…ì¥ëª…": get_text('bplcNm'),
        "ê°œì›ì¼": get_text('apvPermYmd'),
        "ì£¼ì†Œ": get_text('rdnWhlAddr'),
        "ì—…íƒœêµ¬ë¶„": get_text('uptaeNm'),
        "ì „í™”ë²ˆí˜¸": get_text('siteTel'),
        "ê´€ë¦¬ë²ˆí˜¸": get_text('mgtNo')
    }

# ============================================================
# ì¶œë ¥ ë° ì €ì¥ í•¨ìˆ˜ë“¤
# ============================================================

def print_weekly_report(facilities: List[Dict], display_start: str, display_end: str, save_file: Optional[str] = None):
    """ì£¼ê°„ ë¦¬í¬íŠ¸ ì¶œë ¥ (í…Œì´ë¸” í˜•ì‹)"""
    
    # í—¤ë” ì¶œë ¥
    print("\n" + "="*100)
    print(f"ğŸ¥ ê¸ˆì£¼ì˜ ê°œì›ë³‘ì› ë¦¬í¬íŠ¸")
    print(f"ğŸ“… ê¸°ê°„: {display_start} ~ {display_end}")
    print(f"ğŸ¯ ì´ {len(facilities)}ê°œ ì˜ë£Œê¸°ê´€ ê°œì›")
    print("="*100)
    
    if not facilities:
        print("ğŸ“­ í•´ë‹¹ ê¸°ê°„ì— ê°œì›í•œ ì˜ë£Œê¸°ê´€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
    table_data = []
    for facility in facilities:
        # ë‚ ì§œ í˜•ì‹ í†µì¼ (YYYY-MM-DD)
        opening_date = facility['ê°œì›ì¼']
        if opening_date and '-' not in opening_date:
            opening_date = f"{opening_date[:4]}-{opening_date[4:6]}-{opening_date[6:8]}"
        
        # ì£¼ì†Œ ì „ì²´ í‘œì‹œ (ì œí•œ ì—†ìŒ)
        address = facility['ì£¼ì†Œ'] or '-'
        
        # ì „í™”ë²ˆí˜¸ ì²˜ë¦¬
        phone = facility['ì „í™”ë²ˆí˜¸'] or '-'
        
        table_data.append([
            facility['ì—…íƒœêµ¬ë¶„'] or '-',           # êµ¬ë¶„
            facility['ì‚¬ì—…ì¥ëª…'] or '-',           # ì‚¬ì—…ìëª…
            address,                             # ì£¼ì†Œ (ì „ì²´)
            phone,                              # ì „í™”ë²ˆí˜¸
            opening_date or '-'                 # ì¸í—ˆê°€ì¼
        ])
    
    # ê°œì›ì¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    table_data.sort(key=lambda x: x[4])  # ì¸í—ˆê°€ì¼ ì»¬ëŸ¼ìœ¼ë¡œ ì •ë ¬
    
    # í…Œì´ë¸” í—¤ë”
    headers = ["êµ¬ë¶„", "ì‚¬ì—…ìëª…", "ì£¼ì†Œ", "ì „í™”ë²ˆí˜¸", "ì¸í—ˆê°€ì¼"]
    
    # êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ìš© CSV í˜•ì‹
    print("ğŸ“Š êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ìš© ë³µì‚¬ í˜•ì‹")
    print("-" * 120)
    print("â–¼ ì•„ë˜ í…Œì´ë¸”ì„ ë“œë˜ê·¸í•˜ì—¬ êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ë³µì‚¬ ë¶™ì—¬ë„£ê¸° í•˜ì„¸ìš”")
    print()
    
    # CSV í—¤ë” ì¶œë ¥ (ë”°ì˜´í‘œë¡œ ê°ì‹¸ê³  ì‰¼í‘œë¡œ êµ¬ë¶„)
    csv_headers = [f'"{header}"' for header in headers]
    print(",".join(csv_headers))
    
    # CSV ë°ì´í„° ì¶œë ¥ (ì¤„ë°”ê¿ˆ ì œê±°í•˜ê³  ë”°ì˜´í‘œë¡œ ê°ì‹¸ì„œ êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ í˜¸í™˜ì„± í™•ë³´)
    for row in table_data:
        # ê° ì…€ì˜ ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´í•˜ê³  ë”°ì˜´í‘œë¡œ ê°ì‹¸ê¸°
        cleaned_row = [str(cell).replace('\n', ' ').replace('\r', ' ').replace('"', '""').strip() for cell in row]
        csv_row = [f'"{cell}"' for cell in cleaned_row]
        print(",".join(csv_row))
    
    print()
    print("â–² ìœ„ í‘œë¥¼ ë“œë˜ê·¸í•˜ì—¬ ë³µì‚¬í•˜ì„¸ìš” (êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ìš©)")
    print()
    
    # ì¶”ê°€ë¡œ ì¼ë°˜ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ì œê³µ
    print("ğŸ“‹ ì¼ë°˜ í…ìŠ¤íŠ¸ ë²„ì „ (ë°±ì—…ìš©)")
    print("-" * 120)
    
    for i, row in enumerate(table_data, 1):
        êµ¬ë¶„, ì‚¬ì—…ìëª…, ì£¼ì†Œ, ì „í™”ë²ˆí˜¸, ì¸í—ˆê°€ì¼ = row
        
        print(f"{i}. {ì‚¬ì—…ìëª…}")
        print(f"   ğŸ¥ {êµ¬ë¶„}")
        print(f"   ğŸ“… {ì¸í—ˆê°€ì¼}")
        print(f"   ğŸ“ {ì£¼ì†Œ}")
        print(f"   ğŸ“ {ì „í™”ë²ˆí˜¸}")
        print()
    
    # í†µê³„ ì •ë³´
    print("\nğŸ“Š í†µê³„ ì •ë³´")
    print("-" * 50)
    
    # ë‚ ì§œë³„ ë¶„í¬
    by_date = {}
    for facility in facilities:
        date = facility['ê°œì›ì¼']
        if date:
            # ë‚ ì§œ í˜•ì‹ í†µì¼ (YYYY-MM-DD)
            if '-' in date:
                formatted_date = date
            else:
                formatted_date = f"{date[:4]}-{date[4:6]}-{date[6:8]}"
            
            if formatted_date not in by_date:
                by_date[formatted_date] = 0
            by_date[formatted_date] += 1
    
    print(f"ğŸ“… ë‚ ì§œë³„ ë¶„í¬:")
    date_table = [[date, f"{count}ê°œ"] for date, count in sorted(by_date.items())]
    print(tabulate(date_table, headers=["ë‚ ì§œ", "ê°œìˆ˜"], tablefmt="simple"))
    
    # ì§€ì—­ë³„ ë¶„í¬
    regions = {}
    for facility in facilities:
        if facility['ì£¼ì†Œ']:
            region = facility['ì£¼ì†Œ'].split()[0]  # ì²« ë²ˆì§¸ ë‹¨ì–´ (ì‹œ/ë„)
            regions[region] = regions.get(region, 0) + 1
    
    if regions:
        print(f"\nğŸ—ºï¸ ì§€ì—­ë³„ ë¶„í¬:")
        region_table = [[region, f"{count}ê°œ"] for region, count in sorted(regions.items())]
        print(tabulate(region_table, headers=["ì§€ì—­", "ê°œìˆ˜"], tablefmt="simple"))
    
    # ì—…íƒœë³„ ë¶„í¬
    business_types = {}
    for facility in facilities:
        if facility['ì—…íƒœêµ¬ë¶„']:
            business_type = facility['ì—…íƒœêµ¬ë¶„']
            business_types[business_type] = business_types.get(business_type, 0) + 1
    
    if business_types:
        print(f"\nğŸ¥ ì—…íƒœë³„ ë¶„í¬:")
        business_table = [[business_type, f"{count}ê°œ"] for business_type, count in sorted(business_types.items())]
        print(tabulate(business_table, headers=["ì—…íƒœêµ¬ë¶„", "ê°œìˆ˜"], tablefmt="simple"))
    
    # íŒŒì¼ ì €ì¥
    if save_file:
        save_data_to_file(facilities, save_file, display_start, display_end)

def save_data_to_file(facilities: List[Dict], filename: str, start_date: str, end_date: str):
    """ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    report_data = {
        "report_info": {
            "title": "ê¸ˆì£¼ì˜ ê°œì›ë³‘ì› ë¦¬í¬íŠ¸",
            "period": f"{start_date} ~ {end_date}",
            "total_count": len(facilities),
            "generated_at": datetime.now().isoformat()
        },
        "facilities": facilities
    }
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ë°ì´í„°ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

# ============================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ê¸ˆì£¼ì˜ ê°œì›ë³‘ì› ë°ì´í„° ì¶”ì¶œê¸°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  %(prog)s                                # í•˜ë“œì½”ë”© ëª¨ë“œ (íŒŒì¼ ìƒë‹¨ HARDCODED_START_DATE/END_DATE ì‚¬ìš©)
  %(prog)s --week 2025-06-15              # 2025-06-15ê°€ í¬í•¨ëœ ì£¼ì˜ ë°ì´í„°
  %(prog)s --current-week                 # í˜„ì¬ ì£¼ì˜ ë°ì´í„°
  %(prog)s --start-date 2025-06-08 --days 5  # 2025-06-08ë¶€í„° 5ì¼ê°„
  %(prog)s --week 2025-06-15 --save weekly_report.json  # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
  
í•˜ë“œì½”ë”© ëª¨ë“œ ì‚¬ìš©ë²•:
  1. íŒŒì¼ ìƒë‹¨ì˜ HARDCODED_START_DATE, HARDCODED_END_DATE ìˆ˜ì •
  2. python %(prog)s ì‹¤í–‰ (ì¸ì ì—†ì´)
        """
    )
    
    # ë‚ ì§œ ì˜µì…˜ ê·¸ë£¹ (í•˜ë“œì½”ë”© ëª¨ë“œê°€ í™œì„±í™”ë˜ë©´ í•„ìˆ˜ê°€ ì•„ë‹˜)
    date_group = parser.add_mutually_exclusive_group(required=not ENABLE_HARDCODED_MODE)
    date_group.add_argument('--week', type=str, metavar='YYYY-MM-DD',
                           help='í•´ë‹¹ ë‚ ì§œê°€ í¬í•¨ëœ ì£¼ì˜ ì›”ìš”ì¼ë¶€í„° ë°ì´í„° ì¶”ì¶œ')
    date_group.add_argument('--current-week', action='store_true',
                           help='í˜„ì¬ ì£¼ì˜ ë°ì´í„° ì¶”ì¶œ')
    date_group.add_argument('--start-date', type=str, metavar='YYYY-MM-DD',
                           help='ì‹œì‘ ë‚ ì§œ ì§ì ‘ ì§€ì •')
    
    # ê¸°íƒ€ ì˜µì…˜
    parser.add_argument('--days', type=int, default=DEFAULT_DAYS,
                       help=f'ì¶”ì¶œ ê¸°ê°„ (ì¼ìˆ˜, ê¸°ë³¸ê°’: {DEFAULT_DAYS})')
    parser.add_argument('--save', type=str, metavar='FILENAME',
                       help='ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥')
    
    args = parser.parse_args()
    
    # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
    try:
        # í•˜ë“œì½”ë”© ëª¨ë“œ í™•ì¸
        if ENABLE_HARDCODED_MODE and not any([args.current_week, args.week, args.start_date]):
            # í•˜ë“œì½”ë”© ê°’ ì‚¬ìš©
            print(f"ğŸ”§ í•˜ë“œì½”ë”© ëª¨ë“œ: {HARDCODED_START_DATE} ~ {HARDCODED_END_DATE}")
            api_start = HARDCODED_START_DATE
            api_end = HARDCODED_END_DATE
            
            # í‘œì‹œìš© ë‚ ì§œ í˜•ì‹ ë³€í™˜
            start_dt = datetime.strptime(api_start, "%Y%m%d")
            end_dt = datetime.strptime(api_end, "%Y%m%d")
            display_start = format_date_for_display(start_dt)
            display_end = format_date_for_display(end_dt)
            
        elif args.current_week:
            start_date = get_current_week_start()
            api_start, api_end, display_start, display_end = calculate_date_range(start_date, args.days)
        elif args.week:
            start_date = get_week_start_date(args.week)
            api_start, api_end, display_start, display_end = calculate_date_range(start_date, args.days)
        else:  # args.start_date
            start_date = datetime.strptime(args.start_date, "%Y-%m-%d")
            api_start, api_end, display_start, display_end = calculate_date_range(start_date, args.days)
        
    except ValueError as e:
        print(f"âŒ ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {e}")
        print("ì˜¬ë°”ë¥¸ í˜•ì‹: YYYY-MM-DD (ì˜ˆ: 2025-06-15)")
        return
    
    print(f"ğŸ¯ ëª©í‘œ: ê°œì›ì¼ {api_start}~{api_end}ì¸ ëª¨ë“  ì˜ë£Œê¸°ê´€ ì¶”ì¶œ")
    print(f"ğŸ“Š ë‘ DB ì†ŒìŠ¤ì—ì„œ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ í›„ ê°œì›ì¼ ê¸°ì¤€ í•„í„°ë§")
    
    # 1ë‹¨ê³„: bgnYmd/endYmd ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
    print("\n" + "="*60)
    print("ğŸ“Š 1ë‹¨ê³„: bgnYmd/endYmd ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘")
    print("="*60)
    
    bgn_end_data = fetch_medical_data_comprehensive(api_start, api_end, use_bgn_end=True)
    bgn_end_facilities = filter_by_opening_date(bgn_end_data, api_start, api_end)
    
    print(f"\nğŸ” bgnYmd/endYmdì—ì„œ ê°œì›ì¼ {api_start}~{api_end} í•„í„°ë§ ì¤‘...")
    print(f"âœ… bgnYmd/endYmdì—ì„œ {len(bgn_end_facilities)}ê°œ ì˜ë£Œê¸°ê´€ ë°œê²¬")
    
    # 2ë‹¨ê³„: lastModTsBgn/lastModTsEnd ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
    print("\n" + "="*60)
    print("ğŸ“Š 2ë‹¨ê³„: lastModTsBgn/lastModTsEnd ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘")
    print("="*60)
    
    lastmod_data = fetch_medical_data_comprehensive(api_start, api_end, use_bgn_end=False)
    lastmod_facilities = filter_by_opening_date(lastmod_data, api_start, api_end)
    
    print(f"\nğŸ” lastModTsBgn/lastModTsEndì—ì„œ ê°œì›ì¼ {api_start}~{api_end} í•„í„°ë§ ì¤‘...")
    print(f"âœ… lastModTsBgn/lastModTsEndì—ì„œ {len(lastmod_facilities)}ê°œ ì˜ë£Œê¸°ê´€ ë°œê²¬")
    
    # 3ë‹¨ê³„: ì¤‘ë³µ ì œê±° ë° ë°ì´í„° í†µí•©
    print("\n" + "="*60)
    print("ğŸ”„ 3ë‹¨ê³„: ì¤‘ë³µ ì œê±° ë° ë°ì´í„° í†µí•©")
    print("="*60)
    
    # ê´€ë¦¬ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
    all_facilities = {}
    
    # bgnYmd/endYmd ë°ì´í„° ì¶”ê°€
    for facility in bgn_end_facilities:
        mgt_no = facility['ê´€ë¦¬ë²ˆí˜¸']
        if mgt_no:
            facility['ë°ì´í„°ì†ŒìŠ¤'] = 'bgnYmd/endYmd'
            all_facilities[mgt_no] = facility
    
    # lastModTsBgn/lastModTsEnd ë°ì´í„° ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
    duplicates = 0
    for facility in lastmod_facilities:
        mgt_no = facility['ê´€ë¦¬ë²ˆí˜¸']
        if mgt_no:
            if mgt_no not in all_facilities:
                facility['ë°ì´í„°ì†ŒìŠ¤'] = 'lastModTsBgn/lastModTsEnd'
                all_facilities[mgt_no] = facility
            else:
                duplicates += 1
    
    final_facilities = list(all_facilities.values())
    
    print(f"ğŸ“ˆ bgnYmd/endYmd ì†ŒìŠ¤: {len(bgn_end_facilities)}ê°œ")
    print(f"ğŸ“ˆ lastModTsBgn/lastModTsEnd ì†ŒìŠ¤: {len(lastmod_facilities)}ê°œ")
    print(f"ğŸ”„ ì¤‘ë³µ ì œê±°ëœ í•­ëª©: {duplicates}ê°œ")
    print(f"ğŸ¯ ìµœì¢… í†µí•© ê²°ê³¼: {len(final_facilities)}ê°œ")
    
    # ê°œì›ì¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    final_facilities.sort(key=lambda x: x['ê°œì›ì¼'] or '')
    
    # ê²°ê³¼ ì¶œë ¥
    print_weekly_report(final_facilities, display_start, display_end, args.save)

if __name__ == "__main__":
    main()

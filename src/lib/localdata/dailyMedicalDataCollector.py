#!/usr/bin/env python3
"""
ë§¤ì¼ ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘ ë° Supabase ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
ë§¤ì¼ ì˜¤ì „ 7ì‹œì— ì‹¤í–‰ë˜ì–´ ì–´ì œ, ì˜¤ëŠ˜, ì˜¤ëŠ˜ ì´í›„ ì¸í—ˆê°€ì¼ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì—…ë¡œë“œí•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import requests
import time
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
import re
from supabase import create_client, Client
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Supabase ì„¤ì •
SUPABASE_URL = os.getenv("NEXT_PUBLIC_SUPABASE_URL")
SUPABASE_SERVICE_ROLE_KEY = os.getenv("SUPABASE_SERVICE_ROLE")

# API ì„¤ì •
BASE_URL = "http://www.localdata.go.kr/platform/rest/TO0/openDataApi"
AUTH_KEY = "cPf6Cnhiz8tSZsow6jIGOnyndwJnDO2gNz9qLUIYQ90="

# ì˜ë£Œê¸°ê´€ íƒ€ì…ë³„ ì„œë¹„ìŠ¤ ID
SERVICE_IDS = {
    "ë³‘ì›": "01_01_01_P",
    "ì˜ì›": "01_01_02_P", 
    "ì•½êµ­": "01_01_06_P"
}

# ì§„ë£Œê³¼ëª© ì¶”ë¡ ì„ ìœ„í•œ ë§¤í•‘
MEDICAL_SUBJECT_KEYWORDS = {
    # ì˜ì› ê´€ë ¨
    "ë‚´ê³¼": ["ë‚´ê³¼"],
    "ì†Œì•„ì²­ì†Œë…„ê³¼": ["ì†Œì•„", "ì†Œì•„ì²­ì†Œë…„", "ì†Œì•„ê³¼"],
    "ì •í˜•ì™¸ê³¼": ["ì •í˜•ì™¸ê³¼", "ì •í˜•"],
    "í”¼ë¶€ê³¼": ["í”¼ë¶€ê³¼", "í”¼ë¶€"],
    "ì´ë¹„ì¸í›„ê³¼": ["ì´ë¹„ì¸í›„ê³¼", "ì´ë¹„", "ì½”", "ê·€"],
    "ì•ˆê³¼": ["ì•ˆê³¼", "ëˆˆ"],
    "ë¹„ë‡¨ê¸°ê³¼": ["ë¹„ë‡¨ê¸°ê³¼", "ë¹„ë‡¨"],
    "ì‚°ë¶€ì¸ê³¼": ["ì‚°ë¶€ì¸ê³¼", "ì‚°ë¶€", "ì—¬ì„±ì˜ì›", "ì—¬ì„±"],
    "ì •ì‹ ê±´ê°•ì˜í•™ê³¼": ["ì •ì‹ ê³¼", "ì •ì‹ ê±´ê°•", "ì •ì‹ "],
    "ì¬í™œì˜í•™ê³¼": ["ì¬í™œì˜í•™ê³¼", "ì¬í™œ"],
    "ê°€ì •ì˜í•™ê³¼": ["ê°€ì •ì˜í•™ê³¼", "ê°€ì •"],
    "ì‹ ê²½ê³¼": ["ì‹ ê²½ê³¼"],
    "ì‹ ê²½ì™¸ê³¼": ["ì‹ ê²½ì™¸ê³¼"],
    "ì™¸ê³¼": ["ì™¸ê³¼"],
    "ì„±í˜•ì™¸ê³¼": ["ì„±í˜•ì™¸ê³¼", "ì„±í˜•"],
    "ë§ˆì·¨í†µì¦ì˜í•™ê³¼": ["ë§ˆì·¨í†µì¦", "í†µì¦ì˜í•™ê³¼", "í†µì¦", "í˜ì¸"],
    
    # ì¹˜ê³¼ ê´€ë ¨
    "ì¹˜ê³¼": ["ì¹˜ê³¼"],
    
    # í•œì˜ì› ê´€ë ¨
    "í•œì˜ì›": ["í•œì˜ì›", "í•œë°©", "í•œì˜ê³¼"],
}

class DailyMedicalDataCollector:
    """ë§¤ì¼ ì˜ë£Œê¸°ê´€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  Supabaseì— ì—…ë¡œë“œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.supabase = self._create_supabase_client()
        self.today = datetime.now().date()
        self.yesterday = self.today - timedelta(days=1)
        
        # ë§¤ì¼ ìµœì‹  ë°ì´í„° ìˆ˜ì§‘ - ìµœê·¼ 7ì¼ê°„ + í–¥í›„ 3ì¼ê°„ (API ë¯¸ë˜ ë‚ ì§œ ì œí•œ ê³ ë ¤)
        self.date_range_start = self.today - timedelta(days=7)   # ì¼ì£¼ì¼ ì „ë¶€í„°
        self.date_range_end = self.today + timedelta(days=3)     # ì˜¤ëŠ˜ë¶€í„° 3ì¼ í›„ê¹Œì§€
        
        print(f"ğŸ”§ ì¼ì¼ ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”")
        print(f"ğŸ“… ìˆ˜ì§‘ ëŒ€ìƒ: {self.date_range_start} ~ {self.date_range_end}")
        print(f"ğŸ¯ íƒ€ê²Ÿ: ì¸í—ˆê°€ì¼ì´ ìµœê·¼ 7ì¼ê°„({self.date_range_start} ~ {self.today}) ë° í–¥í›„ 3ì¼ê°„ ë°ì´í„°")
    
    def _create_supabase_client(self) -> Optional[Client]:
        """Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:
            print("âŒ Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return None
        
        try:
            return create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)
        except Exception as e:
            print(f"âŒ Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def extract_medical_subjects(self, business_name: str, business_type: str) -> str:
        """ì‚¬ì—…ì¥ëª…ì—ì„œ ì§„ë£Œê³¼ëª©ì„ ì¶”ë¡ """
        if not business_name:
            return ""
        
        # ì•½êµ­ì€ ì§„ë£Œê³¼ëª©ì´ ì—†ìŒ
        if business_type == "ì•½êµ­":
            return ""
        
        # ë³‘ì›ì€ ì¢…í•©ë³‘ì›ì´ ë§ìœ¼ë¯€ë¡œ ê¸°ë³¸ì ìœ¼ë¡œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        if business_type == "ë³‘ì›":
            # íŠ¹ìˆ˜ë³‘ì› ì²´í¬ (ì˜ˆ: XXì •í˜•ì™¸ê³¼ë³‘ì›)
            for subject, keywords in MEDICAL_SUBJECT_KEYWORDS.items():
                for keyword in keywords:
                    if keyword in business_name:
                        return subject
            return ""
        
        # ì˜ì›ì˜ ê²½ìš°
        found_subjects = []
        
        # ê° ì§„ë£Œê³¼ëª© í‚¤ì›Œë“œ í™•ì¸
        for subject, keywords in MEDICAL_SUBJECT_KEYWORDS.items():
            for keyword in keywords:
                if keyword in business_name:
                    if subject not in found_subjects:
                        found_subjects.append(subject)
                    break
        
        # ì°¾ì€ ì§„ë£Œê³¼ëª©ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë°˜í™˜
        if found_subjects:
            return ", ".join(found_subjects)
        
        # ì˜ì›ì¸ë° ì§„ë£Œê³¼ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        if business_type == "ì˜ì›" and "ì˜ì›" in business_name:
            return "ì¼ë°˜ì˜ì›"
        
        return ""
    
    def fetch_medical_data_for_date_range(self) -> Dict[str, List[Dict]]:
        """ë‚ ì§œ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘"""
        all_facilities = {
            "ë³‘ì›": [],
            "ì˜ì›": [],
            "ì•½êµ­": []
        }
        
        for facility_type, service_id in SERVICE_IDS.items():
            print(f"\nğŸ¥ {facility_type} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            # API ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            start_str = self.date_range_start.strftime("%Y%m%d")
            end_str = self.date_range_end.strftime("%Y%m%d")
            
            # ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘
            # 1. ì¸í—ˆê°€ì¼ ê¸°ì¤€
            facilities_by_permit = self._fetch_by_date_params(
                start_str, end_str, service_id, facility_type, use_bgn_end=True
            )
            
            # 2. ë°ì´í„°ê°±ì‹ ì¼ ê¸°ì¤€
            facilities_by_update = self._fetch_by_date_params(
                start_str, end_str, service_id, facility_type, use_bgn_end=False
            )
            
            # ì¤‘ë³µ ì œê±° ë° í†µí•©
            combined_facilities = self._merge_and_deduplicate(
                facilities_by_permit, facilities_by_update
            )
            
            # ë‚ ì§œ í•„í„°ë§ (ì–´ì œ, ì˜¤ëŠ˜, ì˜¤ëŠ˜ ì´í›„)
            filtered_facilities = self._filter_by_target_dates(combined_facilities)
            
            all_facilities[facility_type] = filtered_facilities
            
            print(f"âœ… {facility_type}: {len(filtered_facilities)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
        
        return all_facilities
    
    def _fetch_by_date_params(self, start_date: str, end_date: str, 
                             service_id: str, facility_type: str, 
                             use_bgn_end: bool = True) -> List[Dict]:
        """APIë¥¼ í†µí•´ ë°ì´í„° ìˆ˜ì§‘"""
        all_data = []
        page_index = 1
        
        print(f"   ğŸ” {'ì¸í—ˆê°€ì¼' if use_bgn_end else 'ë°ì´í„°ê°±ì‹ ì¼'} ê¸°ì¤€ ê²€ìƒ‰: {start_date} ~ {end_date}")
        
        while True:
            params = {
                "authKey": AUTH_KEY,
                "opnSvcId": service_id,
                "pageSize": "1000",
                "pageIndex": str(page_index)
            }
            
            if use_bgn_end:
                params["bgnYmd"] = start_date
                params["endYmd"] = end_date
            else:
                # ë°ì´í„°ê°±ì‹ ì¼ ê¸°ì¤€ ê²€ìƒ‰ - ë™ì ìœ¼ë¡œ ìµœê·¼ 5ì¼ê°„ ë²”ìœ„ ì„¤ì •
                # ì˜¤ëŠ˜ ê¸°ì¤€ìœ¼ë¡œ ì´ì „ 5ì¼ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€
                today = datetime.now().date()
                search_start_date = today - timedelta(days=5)
                search_end_date = today
                
                search_start = search_start_date.strftime("%Y%m%d")
                search_end = search_end_date.strftime("%Y%m%d")
                
                params["lastModTsBgn"] = search_start
                params["lastModTsEnd"] = search_end
            
            try:
                # ì²« í˜ì´ì§€ì—ì„œë§Œ íŒŒë¼ë¯¸í„° ì¶œë ¥
                if page_index == 1:
                    print(f"   ğŸ“‹ API íŒŒë¼ë¯¸í„°: {params}")
                
                response = requests.get(BASE_URL, params=params, timeout=30)
                response.raise_for_status()
                
                # ì‘ë‹µ í˜•ì‹ í™•ì¸
                content_type = response.headers.get('Content-Type', '').lower()
                
                # XML ë˜ëŠ” JSON ì‘ë‹µ ì²˜ë¦¬
                data = None
                rows = []
                total_count = 0
                
                if 'xml' in content_type:
                    # XML íŒŒì‹±
                    try:
                        root = ET.fromstring(response.text)
                        
                        # XMLì—ì„œ rows ì¶”ì¶œ
                        xml_rows = root.findall('.//row')
                        
                        # XML rowë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                        for xml_row in xml_rows:
                            row_dict = {}
                            for child in xml_row:
                                row_dict[child.tag] = child.text if child.text else ""
                            rows.append(row_dict)
                        
                        # ì „ì²´ ê°œìˆ˜ ì¶”ì¶œ (ì²« í˜ì´ì§€ë§Œ)
                        if page_index == 1:
                            total_count_elem = root.find('.//totalCount')
                            if total_count_elem is not None:
                                total_count = int(total_count_elem.text or 0)
                            else:
                                total_count = len(rows)  # fallback
                        
                    except ET.ParseError as pe:
                        print(f"   âŒ XML íŒŒì‹± ì—ëŸ¬: {pe}")
                        break
                else:
                    # JSON íŒŒì‹± (ê¸°ì¡´ ë¡œì§)
                    try:
                        data = response.json()
                        
                        # ì²« í˜ì´ì§€ì—ì„œë§Œ ì‘ë‹µ êµ¬ì¡° í™•ì¸
                        if page_index == 1:
                            if "result" in data and "header" in data["result"] and "paging" in data["result"]["header"]:
                                total_count = data["result"]["header"]["paging"].get("totalCount", 0)
                        
                        # ë°ì´í„° ì¶”ì¶œ
                        rows = self._extract_rows_from_response(data)
                        
                    except json.JSONDecodeError as je:
                        print(f"   âŒ JSON íŒŒì‹± ì—ëŸ¬: {je}")
                        break
                
                # ì²« í˜ì´ì§€ì—ì„œë§Œ ì „ì²´ ê°œìˆ˜ ì¶œë ¥
                if page_index == 1:
                    print(f"   ğŸ“Š API ì „ì²´ ë°ì´í„° ìˆ˜: {total_count}")
                    print(f"   ğŸ“‹ ì‘ë‹µ í˜•ì‹: {'XML' if 'xml' in content_type else 'JSON'}")
                
                print(f"   ğŸ“„ í˜ì´ì§€ {page_index}: {len(rows)}ê°œ í–‰ ë°œê²¬")
                
                if not rows:
                    break
                
                # ë°ì´í„° ë³€í™˜ ë° ë¡œê·¸
                page_converted = 0
                for row in rows:
                    if isinstance(row, dict):
                        facility_data = self._extract_facility_info(row, facility_type)
                        if facility_data:
                            all_data.append(facility_data)
                            page_converted += 1
                
                print(f"   âœï¸ í˜ì´ì§€ {page_index}: {page_converted}ê°œ ë³€í™˜ ì™„ë£Œ")
                
                # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                if len(rows) < 1000:
                    break
                
                page_index += 1
                if page_index > 10:  # ìµœëŒ€ 10í˜ì´ì§€ê¹Œì§€ë§Œ
                    break
                
                time.sleep(0.5)  # API ì œí•œ ë°©ì§€
                
            except Exception as e:
                print(f"   âŒ API í˜¸ì¶œ ì—ëŸ¬ (í˜ì´ì§€ {page_index}): {e}")
                break
        
        print(f"   ğŸ¯ ì´ {len(all_data)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        return all_data
    
    def _extract_rows_from_response(self, data: Dict) -> List:
        """API ì‘ë‹µì—ì„œ ë°ì´í„° í–‰ ì¶”ì¶œ"""
        rows = []
        
        # ë‹¤ì–‘í•œ ì‘ë‹µ êµ¬ì¡° ì²˜ë¦¬
        if "result" in data and "body" in data["result"]:
            body = data["result"]["body"]
            
            if isinstance(body, dict):
                if "rows" in body:
                    rows_data = body["rows"]
                    if isinstance(rows_data, list) and len(rows_data) > 0:
                        if isinstance(rows_data[0], dict) and "row" in rows_data[0]:
                            rows = rows_data[0]["row"]
                        else:
                            rows = rows_data
                else:
                    rows = [body]
            elif isinstance(body, list):
                rows = body
        elif "body" in data:
            rows = data["body"]
        elif "row" in data:
            rows = data["row"]
        
        # ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if not isinstance(rows, list):
            rows = [rows] if rows else []
        
        return rows
    
    def _extract_facility_info(self, row: Dict, facility_type: str) -> Optional[Dict]:
        """API ì‘ë‹µì—ì„œ ì‹œì„¤ ì •ë³´ ì¶”ì¶œ"""
        if not isinstance(row, dict):
            return None
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        if not row.get("mgtNo") or not row.get("apvPermYmd"):
            return None
        
        # ì‚¬ì—…ì¥ëª… ì¶”ì¶œ
        business_name = row.get("bplcNm", "")
        
        # ì§„ë£Œê³¼ëª© ì¶”ë¡ 
        medical_subjects = self.extract_medical_subjects(
            business_name, 
            facility_type
        )
        
        return {
            "ê´€ë¦¬ë²ˆí˜¸": row.get("mgtNo", ""),
            "ì‹œì„¤ìœ í˜•": facility_type,
            "ì‚¬ì—…ì¥ëª…": business_name,
            "ì—…íƒœêµ¬ë¶„": row.get("uptaeNm", ""),
            "ì£¼ì†Œ": row.get("rdnWhlAddr", ""),
            "ì „í™”ë²ˆí˜¸": row.get("siteTel", ""),
            "ê°œì›ì¼": row.get("apvPermYmd", ""),
            "ì§„ë£Œê³¼ëª©": medical_subjects,
            "ê°œë°©ì„œë¹„ìŠ¤ëª…": row.get("opnSvcNm", "")
        }
    
    def _merge_and_deduplicate(self, list1: List[Dict], list2: List[Dict]) -> List[Dict]:
        """ë‘ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³‘í•©í•˜ê³  ì¤‘ë³µ ì œê±°"""
        all_facilities = {}
        
        # ì²« ë²ˆì§¸ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
        for facility in list1:
            mgt_no = facility.get("ê´€ë¦¬ë²ˆí˜¸")
            if mgt_no:
                all_facilities[mgt_no] = facility
        
        # ë‘ ë²ˆì§¸ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
        for facility in list2:
            mgt_no = facility.get("ê´€ë¦¬ë²ˆí˜¸")
            if mgt_no and mgt_no not in all_facilities:
                all_facilities[mgt_no] = facility
        
        return list(all_facilities.values())
    
    def _filter_by_target_dates(self, facilities: List[Dict]) -> List[Dict]:
        """ìµœê·¼ 7ì¼ê°„ ë° í–¥í›„ 30ì¼ê°„ ë‚ ì§œë§Œ í•„í„°ë§"""
        filtered = []
        
        # ë™ì  ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
        start_str = self.date_range_start.strftime("%Y%m%d")
        end_str = self.date_range_end.strftime("%Y%m%d")
        
        print(f"   ğŸ—“ï¸ ë‚ ì§œ í•„í„°ë§: {start_str} ~ {end_str} ë²”ìœ„ ë°ì´í„°ë§Œ í¬í•¨")
        print(f"   ğŸ“‹ í•„í„°ë§ ì „ ë°ì´í„°: {len(facilities)}ê°œ")
        
        for facility in facilities:
            open_date = facility.get("ê°œì›ì¼", "")
            if not open_date:
                continue
            
            # ë‚ ì§œ í˜•ì‹ ì •ê·œí™”
            if "-" in open_date:
                open_date = open_date.replace("-", "")
            
            # ìµœê·¼ 7ì¼ê°„ ë° í–¥í›„ 30ì¼ê°„ ë°ì´í„°ë§Œ í¬í•¨
            if start_str <= open_date <= end_str:
                filtered.append(facility)
                print(f"     âœ… í¬í•¨: {facility.get('ì‚¬ì—…ì¥ëª…', 'N/A')} (ì¸í—ˆê°€ì¼: {open_date})")
            else:
                print(f"     âŒ ì œì™¸: {facility.get('ì‚¬ì—…ì¥ëª…', 'N/A')} (ì¸í—ˆê°€ì¼: {open_date}) - ë²”ìœ„ ë°–")
        
        print(f"   ğŸ“‹ í•„í„°ë§ í›„ ë°ì´í„°: {len(filtered)}ê°œ")
        return filtered
    
    def prepare_for_medical_facilities_table(self, facility: Dict, facility_type: str) -> Dict:
        """medical_facilities í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ë³€í™˜"""
        # ê°œì›ì¼ ì²˜ë¦¬
        license_date = None
        if facility.get('ê°œì›ì¼'):
            date_str = facility['ê°œì›ì¼'].replace('-', '')
            try:
                parsed_date = datetime.strptime(date_str, '%Y%m%d')
                license_date = parsed_date.date().isoformat()
            except ValueError:
                print(f"âš ï¸ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {facility['ê°œì›ì¼']}")
        
        # ì‹œì„¤ ìœ í˜•ë³„ service_nameê³¼ service_id ë§¤í•‘
        service_mapping = {
            'ë³‘ì›': {'service_name': 'ë³‘ì›', 'service_id': '01_01_01_P'},
            'ì˜ì›': {'service_name': 'ì˜ì›', 'service_id': '01_01_02_P'},
            'ì•½êµ­': {'service_name': 'ì•½êµ­', 'service_id': '01_02_01_P'}
        }
        
        service_info = service_mapping.get(facility_type, {
            'service_name': facility_type, 
            'service_id': 'unknown'
        })
        
        return {
            'service_name': service_info['service_name'],
            'service_id': service_info['service_id'],
            'management_number': facility.get('ê´€ë¦¬ë²ˆí˜¸', ''),
            'business_name': facility.get('ì‚¬ì—…ì¥ëª…', ''),
            'business_type': facility.get('ì—…íƒœêµ¬ë¶„', ''),
            'license_date': license_date,
            'road_full_address': facility.get('ì£¼ì†Œ', ''),
            'location_phone': facility.get('ì „í™”ë²ˆí˜¸', ''),
            'medical_subject_names': facility.get('ì§„ë£Œê³¼ëª©', ''),
            'business_status': 'ì˜ì—…/ì •ìƒ',
            'business_status_code': '1',
            'detailed_business_status': 'ì˜ì—…ì¤‘',
            'detailed_business_status_code': '13',
            'data_update_type': 'I',
            'data_update_date': datetime.now().isoformat(),
            'last_modified_time': datetime.now().isoformat()
        }
    
    def upload_to_supabase(self, facilities_by_type: Dict[str, List[Dict]]) -> bool:
        """Supabase medical_facilities í…Œì´ë¸”ì— ë°ì´í„° ì—…ë¡œë“œ"""
        if not self.supabase:
            print("âŒ Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        print("\nğŸš€ Supabase medical_facilities í…Œì´ë¸”ì— ë°ì´í„° ì—…ë¡œë“œ ì‹œì‘...")
        
        total_uploaded = 0
        total_errors = 0
        total_duplicates = 0
        
        for facility_type, facilities in facilities_by_type.items():
            if not facilities:
                continue
            
            print(f"\nğŸ“¤ {facility_type} ë°ì´í„° ì—…ë¡œë“œ ì¤‘... ({len(facilities)}ê°œ)")
            
            # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
            batch_data = []
            for facility in facilities:
                if not facility.get('ê´€ë¦¬ë²ˆí˜¸'):
                    print(f"âš ï¸ ê´€ë¦¬ë²ˆí˜¸ê°€ ì—†ëŠ” ì‹œì„¤ ê±´ë„ˆëœ€: {facility.get('ì‚¬ì—…ì¥ëª…', 'Unknown')}")
                    total_errors += 1
                    continue
                
                facility_data = self.prepare_for_medical_facilities_table(facility, facility_type)
                batch_data.append(facility_data)
            
            if not batch_data:
                print(f"âš ï¸ {facility_type}: ì—…ë¡œë“œí•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤í–‰ (ì¤‘ë³µ ë°ì´í„°ëŠ” ê´€ë¦¬ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì—…ë°ì´íŠ¸)
            try:
                # ë¨¼ì € ê¸°ì¡´ ë°ì´í„° í™•ì¸
                existing_mgt_numbers = [d['management_number'] for d in batch_data]
                existing_check = self.supabase.table('medical_facilities').select('management_number').in_('management_number', existing_mgt_numbers).execute()
                
                existing_set = {row['management_number'] for row in existing_check.data}
                
                # ìƒˆë¡œìš´ ë°ì´í„°ì™€ ì—…ë°ì´íŠ¸í•  ë°ì´í„° ë¶„ë¦¬
                new_data = []
                update_data = []
                
                for data in batch_data:
                    if data['management_number'] in existing_set:
                        update_data.append(data)
                        total_duplicates += 1
                    else:
                        new_data.append(data)
                
                # ìƒˆ ë°ì´í„° ì‚½ì…
                if new_data:
                    insert_result = self.supabase.table('medical_facilities').insert(new_data).execute()
                    total_uploaded += len(insert_result.data) if insert_result.data else 0
                
                # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ (ì„ íƒì‚¬í•­ - í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
                # for data in update_data:
                #     self.supabase.table('medical_facilities').update(data).eq('management_number', data['management_number']).execute()
                
                print(f"âœ… {facility_type}: ì‹ ê·œ {len(new_data)}ê°œ, ì¤‘ë³µ {len(update_data)}ê°œ")
                
            except Exception as e:
                print(f"âŒ {facility_type} ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
                total_errors += len(batch_data)
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“Š ì—…ë¡œë“œ ê²°ê³¼ ìš”ì•½:")
        print(f"   âœ… ì‹ ê·œ ë“±ë¡: {total_uploaded}ê°œ")
        print(f"   ğŸ”„ ì¤‘ë³µ ì œì™¸: {total_duplicates}ê°œ")  
        print(f"   âŒ ì‹¤íŒ¨: {total_errors}ê°œ")
        print(f"   ğŸ“ˆ ì´ ì²˜ë¦¬: {total_uploaded + total_duplicates + total_errors}ê°œ")
        
        return total_uploaded > 0
    
    def save_daily_report(self, facilities_by_type: Dict[str, List[Dict]]):
        """ì¼ì¼ ìˆ˜ì§‘ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        report_data = {
            "collection_date": datetime.now().isoformat(),
            "target_dates": {
                "yesterday": self.yesterday.isoformat(),
                "today": self.today.isoformat(),
                "future": f"{self.today} ì´í›„"
            },
            "statistics": {
                facility_type: len(facilities)
                for facility_type, facilities in facilities_by_type.items()
            },
            "total_count": sum(len(facilities) for facilities in facilities_by_type.values()),
            "facilities_by_type": facilities_by_type
        }
        
        # íŒŒì¼ëª…ì— ì˜¤ëŠ˜ ë‚ ì§œ í¬í•¨
        filename = f"daily_medical_data_{self.today.strftime('%Y%m%d')}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ ì¼ì¼ ë¦¬í¬íŠ¸ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        print("\nğŸ¥ ì¼ì¼ ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print(f"ğŸ“… ì‹¤í–‰ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)
        
        # 1. ë°ì´í„° ìˆ˜ì§‘
        facilities_by_type = self.fetch_medical_data_for_date_range()
        
        # 2. ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
        total_count = sum(len(facilities) for facilities in facilities_by_type.values())
        print(f"\nğŸ“Š ìˆ˜ì§‘ ì™„ë£Œ: ì´ {total_count}ê°œ ì˜ë£Œê¸°ê´€")
        for facility_type, facilities in facilities_by_type.items():
            print(f"   - {facility_type}: {len(facilities)}ê°œ")
        
        # 3. Supabase ì—…ë¡œë“œ
        if total_count > 0:
            upload_success = self.upload_to_supabase(facilities_by_type)
            
            # 4. ì¼ì¼ ë¦¬í¬íŠ¸ ì €ì¥
            self.save_daily_report(facilities_by_type)
            
            if upload_success:
                print("\nâœ… ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                return 0
            else:
                print("\nâš ï¸ ë°ì´í„° ìˆ˜ì§‘ì€ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ì—…ë¡œë“œ ì¤‘ ì¼ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                return 1
        else:
            print("\nğŸ“­ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    collector = DailyMedicalDataCollector()
    return collector.run()


if __name__ == "__main__":
    sys.exit(main()) 
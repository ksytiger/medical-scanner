#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í†µí•© ì˜ë£Œê¸°ê´€ ë°ì´í„° ì¶”ì¶œê¸°
Integrated Medical Facility Data Extractor

ì‚¬ìš©ë²•:
  python integratedMedicalData.py                            # í•˜ë“œì½”ë”© ëª¨ë“œ (íŒŒì¼ ìƒë‹¨ì—ì„œ ë‚ ì§œ ì„¤ì •)
  python integratedMedicalData.py --week 2025-06-15          # í•´ë‹¹ ì£¼ ì›”ìš”ì¼ë¶€í„° 5ì¼ê°„
  python integratedMedicalData.py --current-week             # í˜„ì¬ ì£¼
  python integratedMedicalData.py --start-date 2025-06-08 --days 5  # ì§ì ‘ ë‚ ì§œ ì§€ì •
  python integratedMedicalData.py --upload-to-supabase       # Supabaseì— ì—…ë¡œë“œ
  python integratedMedicalData.py --help                     # ë„ì›€ë§

ì‘ì„±ì: AI Assistant
ìµœì¢… ìˆ˜ì •: 2025-01-27
"""

import requests
import xml.etree.ElementTree as ET
import argparse
import json
import os
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional
from tabulate import tabulate

# Supabase ê´€ë ¨ import (ì„ íƒì‚¬í•­)
try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    print("âš ï¸ supabase-py ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    print("   Supabase ì—…ë¡œë“œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
    print("   pip install supabase")

# ============================================================
# ì„¤ì • ë° ìƒìˆ˜
# ============================================================

# ===== í•˜ë“œì½”ë”© ì„¤ì • (ëª…ë ¹í–‰ ì¸ì ì—†ì´ ì‹¤í–‰í•  ë•Œ ì‚¬ìš©) =====
HARDCODED_START_DATE = "20250601"  # ì‹œì‘ ë‚ ì§œ (YYYYMMDD) - ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”!
HARDCODED_END_DATE = "20250630"    # ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD) - ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”!
ENABLE_HARDCODED_MODE = True       # True: í•˜ë“œì½”ë”© ëª¨ë“œ í™œì„±í™”, False: ëª…ë ¹í–‰ ì¸ì í•„ìˆ˜

# Supabase ì„¤ì •
SUPABASE_URL = os.getenv('NEXT_PUBLIC_SUPABASE_URL')
SUPABASE_SERVICE_ROLE_KEY = os.getenv('SUPABASE_SERVICE_ROLE')

# API ì„¤ì •
API_URL = "http://www.localdata.go.kr/platform/rest/TO0/openDataApi"
AUTH_KEYS = [
    "k8ClVr9qMtXeZqrlBAgXAraxYweS6wAY4aabuXLwMtA=",  # ê¸°ë³¸ í‚¤
    "89dp30YYjiDahshFV4xPe11tJPooygtb9/z3XtSB2EU="   # ë°±ì—… í‚¤
]

# ì˜ë£Œê¸°ê´€ ì„œë¹„ìŠ¤ ID ë§µí•‘
SERVICE_IDS = {
    "ë³‘ì›": "01_01_01_P",
    "ì˜ì›": "01_01_02_P",
    "ì•½êµ­": "01_01_06_P"
}

# ê¸°ë³¸ ì„¤ì •
DEFAULT_DAYS = 5  # ê¸°ë³¸ ê¸°ê°„ (5ì¼)
MAX_PAGES_PER_RANGE = 20  # ê° ë‚ ì§œ ë²”ìœ„ë‹¹ ìµœëŒ€ í˜ì´ì§€ ìˆ˜
PAGE_SIZE_BGN_END = 500
PAGE_SIZE_LASTMOD = 300

# ì‹œì„¤ ìœ í˜• ë§¤í•‘
FACILITY_TYPE_MAPPING = {
    "ë³‘ì›": "hospital",
    "ì˜ì›": "clinic", 
    "ì•½êµ­": "pharmacy"
}

# ì—…íƒœêµ¬ë¶„ë³„ ê³ ì • ì§„ë£Œê³¼ëª© ë§¤í•‘ (íŠ¹ìˆ˜ ë¶„ë¥˜)
FIXED_MEDICAL_SUBJECTS = {
    "ì¹˜ê³¼ì˜ì›": "ì¹˜ê³¼",
    "ì¹˜ê³¼ë³‘ì›": "ì¹˜ê³¼", 
    "í•œì˜ì›": "í•œì˜í•™",
    "í•œë°©ë³‘ì›": "í•œì˜í•™",
    "ìš”ì–‘ë³‘ì›(ì¼ë°˜ìš”ì–‘ë³‘ì›)": "ì¬í™œì˜í•™ê³¼",
    "ì •ì‹ ë³‘ì›": "ì •ì‹ ê±´ê°•ì˜í•™ê³¼",
    "ë³´ê±´ì†Œ": "ì˜ˆë°©ì˜í•™ê³¼",
    "ë³´ê±´ì§€ì†Œ": "ê°€ì •ì˜í•™ê³¼", 
    "ë³´ê±´ì§„ë£Œì†Œ": "ê°€ì •ì˜í•™ê³¼",
    "ì¡°ì‚°ì›": "ì‚°ë¶€ì¸ê³¼",
    "ì•½êµ­": "",  # ì•½êµ­ì€ ì§„ë£Œê³¼ëª© ì—†ìŒ
}

# ì‚¬ì—…ì¥ëª…ì—ì„œ ì¶”ì¶œí•  ì§„ë£Œê³¼ëª© í‚¤ì›Œë“œ (ìš°ì„ ìˆœìœ„ ìˆœ)
MEDICAL_SUBJECT_KEYWORDS = [
    # ë‚´ê³¼ ê³„ì—´
    "ë‚´ë¶„ë¹„ë‚´ê³¼", "ì†Œí™”ê¸°ë‚´ê³¼", "ìˆœí™˜ê¸°ë‚´ê³¼", "í˜¸í¡ê¸°ë‚´ê³¼", "ì‹ ì¥ë‚´ê³¼", "í˜ˆì•¡ë‚´ê³¼", "ê°ì—¼ë‚´ê³¼", "ë¥˜ë§ˆí‹°ìŠ¤ë‚´ê³¼", "ë‚´ê³¼",
    
    # ì™¸ê³¼ ê³„ì—´  
    "ì„±í˜•ì™¸ê³¼", "ì •í˜•ì™¸ê³¼", "ì‹ ê²½ì™¸ê³¼", "í‰ë¶€ì™¸ê³¼", "ì‹¬ì¥ì™¸ê³¼", "ê°„ë‹´ì·Œì™¸ê³¼", "ëŒ€ì¥í•­ë¬¸ì™¸ê³¼", "ìœ ë°©ì™¸ê³¼", "ì™¸ê³¼",
    
    # ì „ë¬¸ê³¼
    "ì‚°ë¶€ì¸ê³¼", "ì†Œì•„ì²­ì†Œë…„ê³¼", "ì†Œì•„ê³¼", "ì²­ì†Œë…„ê³¼", "ì •ì‹ ê±´ê°•ì˜í•™ê³¼", "ì •ì‹ ê³¼", "ê°€ì •ì˜í•™ê³¼", "ì‘ê¸‰ì˜í•™ê³¼",
    "ì¬í™œì˜í•™ê³¼", "ì˜ìƒì˜í•™ê³¼", "ë³‘ë¦¬ê³¼", "ì§„ë‹¨ê²€ì‚¬ì˜í•™ê³¼", "ë§ˆì·¨í†µì¦ì˜í•™ê³¼", "ì˜ˆë°©ì˜í•™ê³¼", "ì§ì—…í™˜ê²½ì˜í•™ê³¼",
    
    # ê°ê°ê¸°ê´€
    "ì•ˆê³¼", "ì´ë¹„ì¸í›„ê³¼", "í”¼ë¶€ê³¼", "ë¹„ë‡¨ì˜í•™ê³¼", "ë¹„ë‡¨ê¸°ê³¼",
    
    # ê¸°íƒ€
    "ì‹ ê²½ê³¼", "ê²°í•µê³¼", "í•µì˜í•™ê³¼", "ë°©ì‚¬ì„ ì¢…ì–‘í•™ê³¼"
]

# ============================================================
# ë‚ ì§œ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ============================================================

def get_week_start_date(date_str: str) -> datetime:
    """ì£¼ì–´ì§„ ë‚ ì§œê°€ í¬í•¨ëœ ì£¼ì˜ ì›”ìš”ì¼ì„ ë°˜í™˜"""
    date = datetime.strptime(date_str, "%Y-%m-%d")
    # ì›”ìš”ì¼ì„ ì£¼ì˜ ì‹œì‘ìœ¼ë¡œ ì„¤ì • (weekday() 0=ì›”ìš”ì¼)
    days_since_monday = date.weekday()
    monday = date - timedelta(days=days_since_monday)
    return monday

def get_current_week_start() -> datetime:
    """í˜„ì¬ ì£¼ì˜ ì›”ìš”ì¼ì„ ë°˜í™˜"""
    today = datetime.now()
    days_since_monday = today.weekday()
    monday = today - timedelta(days=days_since_monday)
    return monday

def format_date_for_api(date: datetime) -> str:
    """datetimeì„ APIìš© ë‚ ì§œ í˜•ì‹(YYYYMMDD)ìœ¼ë¡œ ë³€í™˜"""
    return date.strftime("%Y%m%d")

def format_date_for_display(date: datetime) -> str:
    """datetimeì„ í‘œì‹œìš© ë‚ ì§œ í˜•ì‹(YYYY-MM-DD)ìœ¼ë¡œ ë³€í™˜"""
    return date.strftime("%Y-%m-%d")

def calculate_date_range(start_date: datetime, days: int) -> Tuple[str, str, str, str]:
    """ì‹œì‘ì¼ê³¼ ê¸°ê°„ìœ¼ë¡œë¶€í„° APIìš© ë° í‘œì‹œìš© ë‚ ì§œ ë²”ìœ„ ê³„ì‚°"""
    end_date = start_date + timedelta(days=days)
    
    api_start = format_date_for_api(start_date)
    api_end = format_date_for_api(end_date)
    display_start = format_date_for_display(start_date)
    display_end = format_date_for_display(end_date)
    
    return api_start, api_end, display_start, display_end

# ============================================================
# ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ë“¤
# ============================================================

def fetch_medical_data_comprehensive(api_start: str, api_end: str, service_id: str, 
                                   facility_type: str, use_bgn_end: bool = True) -> List:
    """í¬ê´„ì  ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘"""
    all_data = []
    page_index = 1
    
    method_name = "bgnYmd/endYmd" if use_bgn_end else "lastModTsBgn/lastModTsEnd"
    print(f"\nğŸš€ [{facility_type}] {method_name} ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    
    # lastModTsBgn/lastModTsEndì˜ ê²½ìš° ì—¬ëŸ¬ ë²”ìœ„ë¥¼ ì‹œë„
    date_ranges = []
    if not use_bgn_end:
        # ëª©í‘œ ë‚ ì§œ ì£¼ë³€ì˜ ì—¬ëŸ¬ ë²”ìœ„ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        start_date = datetime.strptime(api_start, "%Y%m%d")
        
        # ê¸°ë³¸ ë²”ìœ„
        date_ranges.append((api_start, api_end, "ê¸°ë³¸ ë²”ìœ„"))
        
        # ì´ì „ ë²”ìœ„ (1ì£¼ ì „)
        prev_week_start = start_date - timedelta(days=7)
        prev_week_end = start_date - timedelta(days=1)
        date_ranges.append((
            format_date_for_api(prev_week_start),
            format_date_for_api(prev_week_end),
            "ì´ì „ ì£¼ ë²”ìœ„"
        ))
        
        # ì´í›„ ë²”ìœ„ (1ì£¼ í›„)
        next_week_start = start_date + timedelta(days=7)
        next_week_end = start_date + timedelta(days=14)
        date_ranges.append((
            format_date_for_api(next_week_start),
            format_date_for_api(next_week_end),
            "ì´í›„ ì£¼ ë²”ìœ„"
        ))
    
    range_index = 0
    
    while True:
        if use_bgn_end:
            # bgnYmd/endYmd ë°©ì‹
            params = {
                "authKey": AUTH_KEYS[0],
                "opnSvcId": service_id,
                "bgnYmd": api_start,
                "endYmd": api_end,
                "pageSize": PAGE_SIZE_BGN_END,
                "pageIndex": page_index
            }
        else:
            # lastModTsBgn/lastModTsEnd ë°©ì‹ - ì—¬ëŸ¬ ë²”ìœ„ ì‹œë„
            if range_index >= len(date_ranges):
                break
                
            start_date, end_date, range_name = date_ranges[range_index]
            print(f"   ğŸ” {range_name} ì‹œë„: {start_date}~{end_date}")
            
            params = {
                "authKey": AUTH_KEYS[0],
                "opnSvcId": service_id,
                "lastModTsBgn": start_date,
                "lastModTsEnd": end_date,
                "pageSize": PAGE_SIZE_LASTMOD,
                "pageIndex": page_index
            }
        
        print(f"ğŸ“„ í˜ì´ì§€ {page_index} ìš”ì²­...")
        
        response = requests.get(API_URL, params=params)
        
        if response.status_code != 200:
            print(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            if not use_bgn_end:
                range_index += 1
                page_index = 1
                continue
            else:
                break
            
        try:
            root = ET.fromstring(response.text)
        except ET.ParseError as e:
            print(f"âŒ XML íŒŒì‹± ì‹¤íŒ¨: {e}")
            if not use_bgn_end:
                range_index += 1
                page_index = 1
                continue
            else:
                break
            
        rows = root.findall('.//row')
        print(f"   â†’ {len(rows)}ê°œ ë°ì´í„° ìˆ˜ì§‘")
        
        if len(rows) == 0:
            if not use_bgn_end:
                # í˜„ì¬ ë²”ìœ„ì—ì„œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë‹¤ìŒ ë²”ìœ„ë¡œ
                range_index += 1
                page_index = 1
                continue
            else:
                break
            
        all_data.extend(rows)
        page_index += 1
        
        if len(rows) < (PAGE_SIZE_BGN_END if use_bgn_end else PAGE_SIZE_LASTMOD):
            if not use_bgn_end:
                # í˜„ì¬ ë²”ìœ„ ì™„ë£Œ, ë‹¤ìŒ ë²”ìœ„ë¡œ
                range_index += 1
                page_index = 1
                continue
            else:
                break
            
        if page_index > MAX_PAGES_PER_RANGE:
            if not use_bgn_end:
                print(f"   âš ï¸ {range_name}: {page_index-1}í˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘")
                range_index += 1
                page_index = 1
                continue
            else:
                print(f"âš ï¸ ì•ˆì „ì¥ì¹˜: {page_index-1}í˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘ ì™„ë£Œ")
                break
    
    print(f"âœ… [{facility_type}] {method_name}: ì´ {len(all_data)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
    return all_data

def filter_by_opening_date(data: List, start_date: str, end_date: str, facility_type: str) -> List[Dict]:
    """ê°œì›ì¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° í•„í„°ë§"""
    filtered_facilities = []
    
    for row in data:
        apv_perm_ymd = row.find('apvPermYmd')
        if apv_perm_ymd is not None and apv_perm_ymd.text:
            opening_date = apv_perm_ymd.text.strip()
            
            # ë‚ ì§œ í˜•ì‹ í†µì¼ (í•˜ì´í”ˆ ì œê±°)
            normalized_opening_date = opening_date.replace('-', '')
            
            if start_date <= normalized_opening_date <= end_date:
                facility = extract_facility_info(row)
                facility['ì‹œì„¤ìœ í˜•'] = facility_type
                facility['ë°ì´í„°ì†ŒìŠ¤'] = ''  # ë‚˜ì¤‘ì— ì„¤ì •ë¨
                filtered_facilities.append(facility)
    
    return filtered_facilities

def extract_medical_subjects(business_name: str, business_type: str) -> str:
    """ì‚¬ì—…ì¥ëª…ê³¼ ì—…íƒœêµ¬ë¶„ìœ¼ë¡œë¶€í„° ì§„ë£Œê³¼ëª© ì¶”ì¶œ"""
    # 1. ê³ ì • ì§„ë£Œê³¼ëª© ë¨¼ì € í™•ì¸ (ì¹˜ê³¼ì˜ì›, í•œì˜ì› ë“±)
    if business_type in FIXED_MEDICAL_SUBJECTS:
        return FIXED_MEDICAL_SUBJECTS[business_type]
    
    # 2. ì‚¬ì—…ì¥ëª…ì—ì„œ ì§„ë£Œê³¼ëª© í‚¤ì›Œë“œ ì¶”ì¶œ
    if business_name:
        found_subjects = []
        for keyword in MEDICAL_SUBJECT_KEYWORDS:
            if keyword in business_name:
                found_subjects.append(keyword)
        
        # ë°œê²¬ëœ ì§„ë£Œê³¼ëª©ë“¤ì„ ì½¤ë§ˆë¡œ ì—°ê²°
        if found_subjects:
            return ",".join(found_subjects)
    
    # 3. ì•„ë¬´ê²ƒë„ ì°¾ì§€ ëª»í•œ ê²½ìš° ë¹ˆ ë¬¸ìì—´
    return ""

def extract_facility_info(row) -> Dict:
    """XML í–‰ì—ì„œ ì˜ë£Œê¸°ê´€ ì •ë³´ ì¶”ì¶œ"""
    def get_text(element_name):
        element = row.find(element_name)
        return element.text.strip() if element is not None and element.text else None
    
    # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
    business_name = get_text('bplcNm')
    business_type = get_text('uptaeNm')
    
    # ì§„ë£Œê³¼ëª© ì¶”ì¶œ
    medical_subjects = extract_medical_subjects(business_name, business_type)
    
    return {
        "ì‚¬ì—…ì¥ëª…": business_name,
        "ê°œì›ì¼": get_text('apvPermYmd'),
        "ì£¼ì†Œ": get_text('rdnWhlAddr'),
        "ì—…íƒœêµ¬ë¶„": business_type,
        "ì „í™”ë²ˆí˜¸": get_text('siteTel'),
        "ê´€ë¦¬ë²ˆí˜¸": get_text('mgtNo'),
        "ì§„ë£Œê³¼ëª©": medical_subjects
    }

# ============================================================
# í†µí•© ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
# ============================================================

def collect_all_facilities(api_start: str, api_end: str) -> Dict[str, List[Dict]]:
    """ëª¨ë“  ìœ í˜•ì˜ ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘"""
    all_facilities_by_type = {}
    
    for facility_type, service_id in SERVICE_IDS.items():
        print(f"\n{'='*60}")
        print(f"ğŸ¥ {facility_type} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print(f"{'='*60}")
        
        # 1ë‹¨ê³„: bgnYmd/endYmd ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        bgn_end_data = fetch_medical_data_comprehensive(
            api_start, api_end, service_id, facility_type, use_bgn_end=True
        )
        bgn_end_facilities = filter_by_opening_date(bgn_end_data, api_start, api_end, facility_type)
        
        print(f"\nğŸ” [{facility_type}] bgnYmd/endYmdì—ì„œ {len(bgn_end_facilities)}ê°œ ë°œê²¬")
        
        # 2ë‹¨ê³„: lastModTsBgn/lastModTsEnd ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        lastmod_data = fetch_medical_data_comprehensive(
            api_start, api_end, service_id, facility_type, use_bgn_end=False
        )
        lastmod_facilities = filter_by_opening_date(lastmod_data, api_start, api_end, facility_type)
        
        print(f"ğŸ” [{facility_type}] lastModTsBgn/lastModTsEndì—ì„œ {len(lastmod_facilities)}ê°œ ë°œê²¬")
        
        # 3ë‹¨ê³„: ì¤‘ë³µ ì œê±° ë° ë°ì´í„° í†µí•©
        all_facilities = {}
        
        # bgnYmd/endYmd ë°ì´í„° ì¶”ê°€
        for facility in bgn_end_facilities:
            mgt_no = facility['ê´€ë¦¬ë²ˆí˜¸']
            if mgt_no:
                facility['ë°ì´í„°ì†ŒìŠ¤'] = 'bgnYmd/endYmd'
                all_facilities[mgt_no] = facility
        
        # lastModTsBgn/lastModTsEnd ë°ì´í„° ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
        duplicates = 0
        for facility in lastmod_facilities:
            mgt_no = facility['ê´€ë¦¬ë²ˆí˜¸']
            if mgt_no:
                if mgt_no not in all_facilities:
                    facility['ë°ì´í„°ì†ŒìŠ¤'] = 'lastModTsBgn/lastModTsEnd'
                    all_facilities[mgt_no] = facility
                else:
                    duplicates += 1
        
        final_facilities = list(all_facilities.values())
        
        print(f"ğŸ”„ [{facility_type}] ì¤‘ë³µ ì œê±°ëœ í•­ëª©: {duplicates}ê°œ")
        print(f"âœ… [{facility_type}] ìµœì¢… ê²°ê³¼: {len(final_facilities)}ê°œ")
        
        all_facilities_by_type[facility_type] = final_facilities
    
    return all_facilities_by_type

# ============================================================
# ì¶œë ¥ ë° ì €ì¥ í•¨ìˆ˜ë“¤
# ============================================================

def print_integrated_report(facilities_by_type: Dict[str, List[Dict]], 
                          display_start: str, display_end: str, 
                          save_file: Optional[str] = None):
    """í†µí•© ë¦¬í¬íŠ¸ ì¶œë ¥"""
    
    # ì „ì²´ í†µí•© ë°ì´í„° ìƒì„±
    all_facilities = []
    for facility_type, facilities in facilities_by_type.items():
        all_facilities.extend(facilities)
    
    # ê°œì›ì¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    all_facilities.sort(key=lambda x: x['ê°œì›ì¼'] or '')
    
    # í—¤ë” ì¶œë ¥
    print("\n" + "="*100)
    print(f"ğŸ¥ í†µí•© ì˜ë£Œê¸°ê´€ ê°œì› ë¦¬í¬íŠ¸")
    print(f"ğŸ“… ê¸°ê°„: {display_start} ~ {display_end}")
    print(f"ğŸ¯ ì´ {len(all_facilities)}ê°œ ì˜ë£Œê¸°ê´€ ê°œì›")
    for facility_type, facilities in facilities_by_type.items():
        print(f"   - {facility_type}: {len(facilities)}ê°œ")
    print("="*100)
    
    if not all_facilities:
        print("ğŸ“­ í•´ë‹¹ ê¸°ê°„ì— ê°œì›í•œ ì˜ë£Œê¸°ê´€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
    table_data = []
    for facility in all_facilities:
        # ë‚ ì§œ í˜•ì‹ í†µì¼ (YYYY-MM-DD)
        opening_date = facility['ê°œì›ì¼']
        if opening_date and '-' not in opening_date:
            opening_date = f"{opening_date[:4]}-{opening_date[4:6]}-{opening_date[6:8]}"
        
        # ì£¼ì†Œ ì „ì²´ í‘œì‹œ
        address = facility['ì£¼ì†Œ'] or '-'
        
        # ì „í™”ë²ˆí˜¸ ì²˜ë¦¬
        phone = facility['ì „í™”ë²ˆí˜¸'] or '-'
        
        table_data.append([
            facility['ì‹œì„¤ìœ í˜•'],                 # ì‹œì„¤ìœ í˜•
            facility['ì—…íƒœêµ¬ë¶„'] or '-',          # êµ¬ë¶„
            facility['ì‚¬ì—…ì¥ëª…'] or '-',          # ì‚¬ì—…ìëª…
            facility['ì§„ë£Œê³¼ëª©'] or '-',          # ì§„ë£Œê³¼ëª©
            address,                             # ì£¼ì†Œ
            phone,                              # ì „í™”ë²ˆí˜¸
            opening_date or '-',                # ì¸í—ˆê°€ì¼
            facility['ê´€ë¦¬ë²ˆí˜¸'] or '-'          # ê´€ë¦¬ë²ˆí˜¸
        ])
    
    # í…Œì´ë¸” í—¤ë”
    headers = ["ì‹œì„¤ìœ í˜•", "êµ¬ë¶„", "ì‚¬ì—…ìëª…", "ì§„ë£Œê³¼ëª©", "ì£¼ì†Œ", "ì „í™”ë²ˆí˜¸", "ì¸í—ˆê°€ì¼", "ê´€ë¦¬ë²ˆí˜¸"]
    
    # êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ìš© CSV í˜•ì‹
    print("\nğŸ“Š êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ìš© ë³µì‚¬ í˜•ì‹")
    print("-" * 120)
    print("â–¼ ì•„ë˜ í…Œì´ë¸”ì„ ë“œë˜ê·¸í•˜ì—¬ êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ë³µì‚¬ ë¶™ì—¬ë„£ê¸° í•˜ì„¸ìš”")
    print()
    
    # CSV í—¤ë” ì¶œë ¥
    csv_headers = [f'"{header}"' for header in headers]
    print(",".join(csv_headers))
    
    # CSV ë°ì´í„° ì¶œë ¥
    for row in table_data:
        cleaned_row = [str(cell).replace('\n', ' ').replace('\r', ' ').replace('"', '""').strip() for cell in row]
        csv_row = [f'"{cell}"' for cell in cleaned_row]
        print(",".join(csv_row))
    
    print()
    print("â–² ìœ„ í‘œë¥¼ ë“œë˜ê·¸í•˜ì—¬ ë³µì‚¬í•˜ì„¸ìš” (êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ìš©)")
    
    # ìœ í˜•ë³„ ìƒì„¸ ë¦¬ìŠ¤íŠ¸
    print("\n\nğŸ“‹ ìœ í˜•ë³„ ìƒì„¸ ë¦¬ìŠ¤íŠ¸")
    print("="*100)
    
    for facility_type, facilities in facilities_by_type.items():
        if facilities:
            print(f"\nğŸ¥ {facility_type} ({len(facilities)}ê°œ)")
            print("-" * 80)
            
            # ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
            sorted_facilities = sorted(facilities, key=lambda x: x['ê°œì›ì¼'] or '')
            
            for i, facility in enumerate(sorted_facilities, 1):
                opening_date = facility['ê°œì›ì¼']
                if opening_date and '-' not in opening_date:
                    opening_date = f"{opening_date[:4]}-{opening_date[4:6]}-{opening_date[6:8]}"
                
                print(f"{i}. {facility['ì‚¬ì—…ì¥ëª…']}")
                print(f"   ğŸ“‹ {facility['ì—…íƒœêµ¬ë¶„'] or 'ë¶„ë¥˜ì—†ìŒ'}")
                print(f"   ğŸ©º {facility['ì§„ë£Œê³¼ëª©'] or 'ì§„ë£Œê³¼ëª©ì—†ìŒ'}")
                print(f"   ğŸ“… {opening_date}")
                print(f"   ğŸ“ {facility['ì£¼ì†Œ'] or 'ì£¼ì†Œì—†ìŒ'}")
                print(f"   ğŸ“ {facility['ì „í™”ë²ˆí˜¸'] or 'ì „í™”ë²ˆí˜¸ì—†ìŒ'}")
                print(f"   ğŸ†” {facility['ê´€ë¦¬ë²ˆí˜¸'] or 'ê´€ë¦¬ë²ˆí˜¸ì—†ìŒ'}")
                print()
    
    # í†µê³„ ì •ë³´
    print("\nğŸ“Š í†µí•© í†µê³„ ì •ë³´")
    print("="*100)
    
    # ë‚ ì§œë³„ ë¶„í¬
    by_date = {}
    for facility in all_facilities:
        date = facility['ê°œì›ì¼']
        if date:
            if '-' in date:
                formatted_date = date
            else:
                formatted_date = f"{date[:4]}-{date[4:6]}-{date[6:8]}"
            
            if formatted_date not in by_date:
                by_date[formatted_date] = {'ì´ê³„': 0}
            by_date[formatted_date]['ì´ê³„'] += 1
            
            # ìœ í˜•ë³„ ì¹´ìš´íŠ¸
            facility_type = facility['ì‹œì„¤ìœ í˜•']
            if facility_type not in by_date[formatted_date]:
                by_date[formatted_date][facility_type] = 0
            by_date[formatted_date][facility_type] += 1
    
    print(f"\nğŸ“… ë‚ ì§œë³„ ë¶„í¬:")
    date_headers = ["ë‚ ì§œ", "ì´ê³„"] + list(SERVICE_IDS.keys())
    date_table = []
    for date in sorted(by_date.keys()):
        row = [date, f"{by_date[date]['ì´ê³„']}ê°œ"]
        for facility_type in SERVICE_IDS.keys():
            count = by_date[date].get(facility_type, 0)
            row.append(f"{count}ê°œ" if count > 0 else "-")
        date_table.append(row)
    
    print(tabulate(date_table, headers=date_headers, tablefmt="simple"))
    
    # ì§€ì—­ë³„ ë¶„í¬
    regions = {}
    for facility in all_facilities:
        if facility['ì£¼ì†Œ']:
            region = facility['ì£¼ì†Œ'].split()[0]
            if region not in regions:
                regions[region] = {'ì´ê³„': 0}
            regions[region]['ì´ê³„'] += 1
            
            # ìœ í˜•ë³„ ì¹´ìš´íŠ¸
            facility_type = facility['ì‹œì„¤ìœ í˜•']
            if facility_type not in regions[region]:
                regions[region][facility_type] = 0
            regions[region][facility_type] += 1
    
    if regions:
        print(f"\nğŸ—ºï¸ ì§€ì—­ë³„ ë¶„í¬:")
        region_headers = ["ì§€ì—­", "ì´ê³„"] + list(SERVICE_IDS.keys())
        region_table = []
        for region in sorted(regions.keys()):
            row = [region, f"{regions[region]['ì´ê³„']}ê°œ"]
            for facility_type in SERVICE_IDS.keys():
                count = regions[region].get(facility_type, 0)
                row.append(f"{count}ê°œ" if count > 0 else "-")
            region_table.append(row)
        
        print(tabulate(region_table, headers=region_headers, tablefmt="simple"))
    
    # íŒŒì¼ ì €ì¥
    if save_file:
        save_integrated_data(facilities_by_type, save_file, display_start, display_end)

def save_integrated_data(facilities_by_type: Dict[str, List[Dict]], 
                        filename: str, start_date: str, end_date: str):
    """í†µí•© ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    # ì „ì²´ ë°ì´í„° í†µí•©
    all_facilities = []
    for facilities in facilities_by_type.values():
        all_facilities.extend(facilities)
    
    report_data = {
        "report_info": {
            "title": "í†µí•© ì˜ë£Œê¸°ê´€ ê°œì› ë¦¬í¬íŠ¸",
            "period": f"{start_date} ~ {end_date}",
            "total_count": len(all_facilities),
            "count_by_type": {
                facility_type: len(facilities) 
                for facility_type, facilities in facilities_by_type.items()
            },
            "generated_at": datetime.now().isoformat()
        },
        "facilities_by_type": facilities_by_type,
        "all_facilities": all_facilities
    }
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ë°ì´í„°ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

# ============================================================
# Supabase ì—…ë¡œë“œ í•¨ìˆ˜ë“¤
# ============================================================

def create_supabase_client() -> Optional[Client]:
    """Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    if not SUPABASE_AVAILABLE:
        print("âŒ supabase-py ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None
    
    if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:
        print("âŒ Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("   í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜:")
        print("   - NEXT_PUBLIC_SUPABASE_URL")
        print("   - NEXT_SUPABASE_SERVICE_ROLE")
        return None
    
    try:
        return create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)
    except Exception as e:
        print(f"âŒ Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def get_facility_type_id(supabase: Client, facility_type: str) -> Optional[str]:
    """ì‹œì„¤ ìœ í˜• ID ì¡°íšŒ"""
    try:
        slug = FACILITY_TYPE_MAPPING.get(facility_type)
        if not slug:
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì‹œì„¤ ìœ í˜•: {facility_type}")
            return None
        
        result = supabase.table('facility_types').select('id').eq('slug', slug).execute()
        
        if result.data:
            return result.data[0]['id']
        else:
            print(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‹œì„¤ ìœ í˜•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {slug}")
            return None
            
    except Exception as e:
        print(f"âŒ ì‹œì„¤ ìœ í˜• ID ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

def prepare_facility_data_for_medical_facilities(facility: Dict, facility_type: str) -> Dict:
    """ì˜ë£Œê¸°ê´€ ë°ì´í„°ë¥¼ medical_facilities í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    # ê°œì›ì¼ ì²˜ë¦¬
    license_date = None
    if facility.get('ê°œì›ì¼'):
        date_str = facility['ê°œì›ì¼'].replace('-', '')
        try:
            parsed_date = datetime.strptime(date_str, '%Y%m%d')
            license_date = parsed_date.date().isoformat()
        except ValueError:
            print(f"âš ï¸ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {facility['ê°œì›ì¼']}")
    
    # ì‹œì„¤ ìœ í˜•ë³„ service_nameê³¼ service_id ë§¤í•‘
    service_mapping = {
        'ë³‘ì›': {'service_name': 'ë³‘ì›', 'service_id': '01_01_01_P'},
        'ì˜ì›': {'service_name': 'ì˜ì›', 'service_id': '01_01_02_P'},
        'ì•½êµ­': {'service_name': 'ì•½êµ­', 'service_id': '01_02_01_P'}
    }
    
    service_info = service_mapping.get(facility_type, {'service_name': facility_type, 'service_id': 'unknown'})
    
    # medical_facilities í…Œì´ë¸”ì— ë§ëŠ” í•„ë“œëª…ìœ¼ë¡œ ë§¤í•‘
    return {
        'service_name': service_info['service_name'],
        'service_id': service_info['service_id'],
        'management_number': facility.get('ê´€ë¦¬ë²ˆí˜¸', ''),
        'business_name': facility.get('ì‚¬ì—…ì¥ëª…', ''),
        'business_type': facility.get('ì—…íƒœêµ¬ë¶„', ''),
        'license_date': license_date,
        'road_full_address': facility.get('ì£¼ì†Œ', ''),
        'location_phone': facility.get('ì „í™”ë²ˆí˜¸', ''),
        'medical_subject_names': facility.get('ì§„ë£Œê³¼ëª©', ''),
        'business_status': 'ì˜ì—…/ì •ìƒ',
        'business_status_code': '1',
        'detailed_business_status': 'ì˜ì—…ì¤‘',
        'detailed_business_status_code': '13',
        'data_update_type': 'I',
        'data_update_date': datetime.now().isoformat(),
        'last_modified_time': datetime.now().isoformat()
    }

def upload_facilities_to_medical_facilities(facilities_by_type: Dict[str, List[Dict]]) -> bool:
    """ì˜ë£Œê¸°ê´€ ë°ì´í„°ë¥¼ medical_facilities í…Œì´ë¸”ì— ì—…ë¡œë“œ"""
    supabase = create_supabase_client()
    if not supabase:
        return False
    
    print("\nğŸš€ medical_facilities í…Œì´ë¸”ì— ë°ì´í„° ì—…ë¡œë“œ ì‹œì‘...")
    
    total_uploaded = 0
    total_errors = 0
    
    for facility_type, facilities in facilities_by_type.items():
        if not facilities:
            continue
            
        print(f"\nğŸ“¤ {facility_type} ë°ì´í„° ì—…ë¡œë“œ ì¤‘... ({len(facilities)}ê°œ)")
        
        # ë°°ì¹˜ ì—…ë¡œë“œ ì¤€ë¹„
        batch_data = []
        for facility in facilities:
            if not facility.get('ê´€ë¦¬ë²ˆí˜¸'):
                print(f"âš ï¸ ê´€ë¦¬ë²ˆí˜¸ê°€ ì—†ëŠ” ì‹œì„¤ ê±´ë„ˆëœ€: {facility.get('ì‚¬ì—…ì¥ëª…', 'Unknown')}")
                total_errors += 1
                continue
            
            facility_data = prepare_facility_data_for_medical_facilities(facility, facility_type)
            batch_data.append(facility_data)
        
        if not batch_data:
            print(f"âš ï¸ {facility_type}: ì—…ë¡œë“œí•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        # ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤í–‰
        try:
            # upsertë¡œ ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬ (ê´€ë¦¬ë²ˆí˜¸ ê¸°ì¤€)
            result = supabase.table('medical_facilities').upsert(
                batch_data, 
                on_conflict='management_number'
            ).execute()
            
            uploaded_count = len(result.data) if result.data else 0
            print(f"âœ… {facility_type}: {uploaded_count}ê°œ ì—…ë¡œë“œ ì™„ë£Œ")
            total_uploaded += uploaded_count
            
        except Exception as e:
            print(f"âŒ {facility_type} ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            print(f"   ì˜¤ë¥˜ ìƒì„¸: {str(e)}")
            total_errors += len(batch_data)
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“Š ì—…ë¡œë“œ ê²°ê³¼ ìš”ì•½:")
    print(f"   âœ… ì„±ê³µ: {total_uploaded}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨: {total_errors}ê°œ")
    print(f"   ğŸ“ˆ ì´ ì²˜ë¦¬: {total_uploaded + total_errors}ê°œ")
    
    if total_uploaded > 0:
        print(f"\nğŸ‰ medical_facilities í…Œì´ë¸” ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"   ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í™•ì¸í•˜ì„¸ìš”: {SUPABASE_URL}")
        return True
    else:
        print(f"\nğŸ˜ ì—…ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False

# ============================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="í†µí•© ì˜ë£Œê¸°ê´€ ë°ì´í„° ì¶”ì¶œê¸°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  %(prog)s                                # í•˜ë“œì½”ë”© ëª¨ë“œ (íŒŒì¼ ìƒë‹¨ HARDCODED_START_DATE/END_DATE ì‚¬ìš©)
  %(prog)s --week 2025-06-15              # 2025-06-15ê°€ í¬í•¨ëœ ì£¼ì˜ ë°ì´í„°
  %(prog)s --current-week                 # í˜„ì¬ ì£¼ì˜ ë°ì´í„°
  %(prog)s --start-date 2025-06-08 --days 5  # 2025-06-08ë¶€í„° 5ì¼ê°„
  %(prog)s --week 2025-06-15 --save integrated_report.json  # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
  %(prog)s --upload-to-supabase           # í•˜ë“œì½”ë”© ëª¨ë“œë¡œ ë°ì´í„° ìˆ˜ì§‘ í›„ Supabase ì—…ë¡œë“œ
  %(prog)s --week 2025-06-15 --upload-to-supabase  # íŠ¹ì • ì£¼ ë°ì´í„°ë¥¼ Supabaseì— ì—…ë¡œë“œ
  
í•˜ë“œì½”ë”© ëª¨ë“œ ì‚¬ìš©ë²•:
  1. íŒŒì¼ ìƒë‹¨ì˜ HARDCODED_START_DATE, HARDCODED_END_DATE ìˆ˜ì •
  2. python %(prog)s ì‹¤í–‰ (ì¸ì ì—†ì´)

Supabase ì—…ë¡œë“œ ì‚¬ìš©ë²•:
  1. supabase-py ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜: pip install supabase
  2. í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
     export NEXT_PUBLIC_SUPABASE_URL="your_supabase_url"
     export NEXT_SUPABASE_SERVICE_ROLE="your_service_role_key"
  3. --upload-to-supabase ì˜µì…˜ê³¼ í•¨ê»˜ ì‹¤í–‰
        """
    )
    
    # ë‚ ì§œ ì˜µì…˜ ê·¸ë£¹
    date_group = parser.add_mutually_exclusive_group(required=not ENABLE_HARDCODED_MODE)
    date_group.add_argument('--week', type=str, metavar='YYYY-MM-DD',
                           help='í•´ë‹¹ ë‚ ì§œê°€ í¬í•¨ëœ ì£¼ì˜ ì›”ìš”ì¼ë¶€í„° ë°ì´í„° ì¶”ì¶œ')
    date_group.add_argument('--current-week', action='store_true',
                           help='í˜„ì¬ ì£¼ì˜ ë°ì´í„° ì¶”ì¶œ')
    date_group.add_argument('--start-date', type=str, metavar='YYYY-MM-DD',
                           help='ì‹œì‘ ë‚ ì§œ ì§ì ‘ ì§€ì •')
    
    # ê¸°íƒ€ ì˜µì…˜
    parser.add_argument('--days', type=int, default=DEFAULT_DAYS,
                       help=f'ì¶”ì¶œ ê¸°ê°„ (ì¼ìˆ˜, ê¸°ë³¸ê°’: {DEFAULT_DAYS})')
    parser.add_argument('--save', type=str, metavar='FILENAME',
                       help='ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥')
    parser.add_argument('--upload-to-supabase', action='store_true',
                       help='ë°ì´í„°ë¥¼ Supabaseì— ì—…ë¡œë“œ')
    
    args = parser.parse_args()
    
    # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
    try:
        # í•˜ë“œì½”ë”© ëª¨ë“œ í™•ì¸
        if ENABLE_HARDCODED_MODE and not any([args.current_week, args.week, args.start_date]):
            # í•˜ë“œì½”ë”© ê°’ ì‚¬ìš©
            print(f"ğŸ”§ í•˜ë“œì½”ë”© ëª¨ë“œ: {HARDCODED_START_DATE} ~ {HARDCODED_END_DATE}")
            api_start = HARDCODED_START_DATE
            api_end = HARDCODED_END_DATE
            
            # í‘œì‹œìš© ë‚ ì§œ í˜•ì‹ ë³€í™˜
            start_dt = datetime.strptime(api_start, "%Y%m%d")
            end_dt = datetime.strptime(api_end, "%Y%m%d")
            display_start = format_date_for_display(start_dt)
            display_end = format_date_for_display(end_dt)
            
        elif args.current_week:
            start_date = get_current_week_start()
            api_start, api_end, display_start, display_end = calculate_date_range(start_date, args.days)
        elif args.week:
            start_date = get_week_start_date(args.week)
            api_start, api_end, display_start, display_end = calculate_date_range(start_date, args.days)
        else:  # args.start_date
            start_date = datetime.strptime(args.start_date, "%Y-%m-%d")
            api_start, api_end, display_start, display_end = calculate_date_range(start_date, args.days)
        
    except ValueError as e:
        print(f"âŒ ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {e}")
        print("ì˜¬ë°”ë¥¸ í˜•ì‹: YYYY-MM-DD (ì˜ˆ: 2025-06-15)")
        return
    
    print(f"ğŸ¯ ëª©í‘œ: ê°œì›ì¼ {api_start}~{api_end}ì¸ ëª¨ë“  ì˜ë£Œê¸°ê´€ ì¶”ì¶œ")
    print(f"ğŸ“Š ë³‘ì›, ì˜ì›, ì•½êµ­ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
    
    # ëª¨ë“  ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘
    facilities_by_type = collect_all_facilities(api_start, api_end)
    
    # í†µí•© ë¦¬í¬íŠ¸ ì¶œë ¥
    print_integrated_report(facilities_by_type, display_start, display_end, args.save)
    
    # Supabase ì—…ë¡œë“œ
    if args.upload_to_supabase:
        success = upload_facilities_to_medical_facilities(facilities_by_type)
        return 0 if success else 1

if __name__ == "__main__":
    main() 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í†µí•© ì˜ë£Œê¸°ê´€ ë°ì´í„° ì¶”ì¶œê¸°
Integrated Medical Facility Data Extractor

ì‚¬ìš©ë²•:
  python integratedMedicalData.py                            # í•˜ë“œì½”ë”© ëª¨ë“œ (íŒŒì¼ ìƒë‹¨ì—ì„œ ë‚ ì§œ ì„¤ì •)
  python integratedMedicalData.py --week 2025-06-15          # í•´ë‹¹ ì£¼ ì›”ìš”ì¼ë¶€í„° 5ì¼ê°„
  python integratedMedicalData.py --current-week             # í˜„ì¬ ì£¼
  python integratedMedicalData.py --start-date 2025-06-08 --days 5  # ì§ì ‘ ë‚ ì§œ ì§€ì •
  python integratedMedicalData.py --help                     # ë„ì›€ë§

ì‘ì„±ì: AI Assistant
ìµœì¢… ìˆ˜ì •: 2025-01-27
"""

import requests
import xml.etree.ElementTree as ET
import argparse
import json
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional
from tabulate import tabulate

# ============================================================
# ì„¤ì • ë° ìƒìˆ˜
# ============================================================

# ===== í•˜ë“œì½”ë”© ì„¤ì • (ëª…ë ¹í–‰ ì¸ì ì—†ì´ ì‹¤í–‰í•  ë•Œ ì‚¬ìš©) =====
HARDCODED_START_DATE = "20250601"  # ì‹œì‘ ë‚ ì§œ (YYYYMMDD) - ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”!
HARDCODED_END_DATE = "20250619"    # ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD) - ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ì„¸ìš”!
ENABLE_HARDCODED_MODE = True       # True: í•˜ë“œì½”ë”© ëª¨ë“œ í™œì„±í™”, False: ëª…ë ¹í–‰ ì¸ì í•„ìˆ˜

# API ì„¤ì •
API_URL = "http://www.localdata.go.kr/platform/rest/TO0/openDataApi"
AUTH_KEYS = [
    "k8ClVr9qMtXeZqrlBAgXAraxYweS6wAY4aabuXLwMtA=",  # ê¸°ë³¸ í‚¤
    "89dp30YYjiDahshFV4xPe11tJPooygtb9/z3XtSB2EU="   # ë°±ì—… í‚¤
]

# ì˜ë£Œê¸°ê´€ ì„œë¹„ìŠ¤ ID ë§µí•‘
SERVICE_IDS = {
    "ë³‘ì›": "01_01_01_P",
    "ì˜ì›": "01_01_02_P",
    "ì•½êµ­": "01_01_06_P"
}

# ê¸°ë³¸ ì„¤ì •
DEFAULT_DAYS = 5  # ê¸°ë³¸ ê¸°ê°„ (5ì¼)
MAX_PAGES_PER_RANGE = 20  # ê° ë‚ ì§œ ë²”ìœ„ë‹¹ ìµœëŒ€ í˜ì´ì§€ ìˆ˜
PAGE_SIZE_BGN_END = 500
PAGE_SIZE_LASTMOD = 300

# ============================================================
# ë‚ ì§œ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ============================================================

def get_week_start_date(date_str: str) -> datetime:
    """ì£¼ì–´ì§„ ë‚ ì§œê°€ í¬í•¨ëœ ì£¼ì˜ ì›”ìš”ì¼ì„ ë°˜í™˜"""
    date = datetime.strptime(date_str, "%Y-%m-%d")
    # ì›”ìš”ì¼ì„ ì£¼ì˜ ì‹œì‘ìœ¼ë¡œ ì„¤ì • (weekday() 0=ì›”ìš”ì¼)
    days_since_monday = date.weekday()
    monday = date - timedelta(days=days_since_monday)
    return monday

def get_current_week_start() -> datetime:
    """í˜„ì¬ ì£¼ì˜ ì›”ìš”ì¼ì„ ë°˜í™˜"""
    today = datetime.now()
    days_since_monday = today.weekday()
    monday = today - timedelta(days=days_since_monday)
    return monday

def format_date_for_api(date: datetime) -> str:
    """datetimeì„ APIìš© ë‚ ì§œ í˜•ì‹(YYYYMMDD)ìœ¼ë¡œ ë³€í™˜"""
    return date.strftime("%Y%m%d")

def format_date_for_display(date: datetime) -> str:
    """datetimeì„ í‘œì‹œìš© ë‚ ì§œ í˜•ì‹(YYYY-MM-DD)ìœ¼ë¡œ ë³€í™˜"""
    return date.strftime("%Y-%m-%d")

def calculate_date_range(start_date: datetime, days: int) -> Tuple[str, str, str, str]:
    """ì‹œì‘ì¼ê³¼ ê¸°ê°„ìœ¼ë¡œë¶€í„° APIìš© ë° í‘œì‹œìš© ë‚ ì§œ ë²”ìœ„ ê³„ì‚°"""
    end_date = start_date + timedelta(days=days)
    
    api_start = format_date_for_api(start_date)
    api_end = format_date_for_api(end_date)
    display_start = format_date_for_display(start_date)
    display_end = format_date_for_display(end_date)
    
    return api_start, api_end, display_start, display_end

# ============================================================
# ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ë“¤
# ============================================================

def fetch_medical_data_comprehensive(api_start: str, api_end: str, service_id: str, 
                                   facility_type: str, use_bgn_end: bool = True) -> List:
    """í¬ê´„ì  ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘"""
    all_data = []
    page_index = 1
    
    method_name = "bgnYmd/endYmd" if use_bgn_end else "lastModTsBgn/lastModTsEnd"
    print(f"\nğŸš€ [{facility_type}] {method_name} ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    
    # lastModTsBgn/lastModTsEndì˜ ê²½ìš° ì—¬ëŸ¬ ë²”ìœ„ë¥¼ ì‹œë„
    date_ranges = []
    if not use_bgn_end:
        # ëª©í‘œ ë‚ ì§œ ì£¼ë³€ì˜ ì—¬ëŸ¬ ë²”ìœ„ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        start_date = datetime.strptime(api_start, "%Y%m%d")
        
        # ê¸°ë³¸ ë²”ìœ„
        date_ranges.append((api_start, api_end, "ê¸°ë³¸ ë²”ìœ„"))
        
        # ì´ì „ ë²”ìœ„ (1ì£¼ ì „)
        prev_week_start = start_date - timedelta(days=7)
        prev_week_end = start_date - timedelta(days=1)
        date_ranges.append((
            format_date_for_api(prev_week_start),
            format_date_for_api(prev_week_end),
            "ì´ì „ ì£¼ ë²”ìœ„"
        ))
        
        # ì´í›„ ë²”ìœ„ (1ì£¼ í›„)
        next_week_start = start_date + timedelta(days=7)
        next_week_end = start_date + timedelta(days=14)
        date_ranges.append((
            format_date_for_api(next_week_start),
            format_date_for_api(next_week_end),
            "ì´í›„ ì£¼ ë²”ìœ„"
        ))
    
    range_index = 0
    
    while True:
        if use_bgn_end:
            # bgnYmd/endYmd ë°©ì‹
            params = {
                "authKey": AUTH_KEYS[0],
                "opnSvcId": service_id,
                "bgnYmd": api_start,
                "endYmd": api_end,
                "pageSize": PAGE_SIZE_BGN_END,
                "pageIndex": page_index
            }
        else:
            # lastModTsBgn/lastModTsEnd ë°©ì‹ - ì—¬ëŸ¬ ë²”ìœ„ ì‹œë„
            if range_index >= len(date_ranges):
                break
                
            start_date, end_date, range_name = date_ranges[range_index]
            print(f"   ğŸ” {range_name} ì‹œë„: {start_date}~{end_date}")
            
            params = {
                "authKey": AUTH_KEYS[0],
                "opnSvcId": service_id,
                "lastModTsBgn": start_date,
                "lastModTsEnd": end_date,
                "pageSize": PAGE_SIZE_LASTMOD,
                "pageIndex": page_index
            }
        
        print(f"ğŸ“„ í˜ì´ì§€ {page_index} ìš”ì²­...")
        
        response = requests.get(API_URL, params=params)
        
        if response.status_code != 200:
            print(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            if not use_bgn_end:
                range_index += 1
                page_index = 1
                continue
            else:
                break
            
        try:
            root = ET.fromstring(response.text)
        except ET.ParseError as e:
            print(f"âŒ XML íŒŒì‹± ì‹¤íŒ¨: {e}")
            if not use_bgn_end:
                range_index += 1
                page_index = 1
                continue
            else:
                break
            
        rows = root.findall('.//row')
        print(f"   â†’ {len(rows)}ê°œ ë°ì´í„° ìˆ˜ì§‘")
        
        if len(rows) == 0:
            if not use_bgn_end:
                # í˜„ì¬ ë²”ìœ„ì—ì„œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë‹¤ìŒ ë²”ìœ„ë¡œ
                range_index += 1
                page_index = 1
                continue
            else:
                break
            
        all_data.extend(rows)
        page_index += 1
        
        if len(rows) < (PAGE_SIZE_BGN_END if use_bgn_end else PAGE_SIZE_LASTMOD):
            if not use_bgn_end:
                # í˜„ì¬ ë²”ìœ„ ì™„ë£Œ, ë‹¤ìŒ ë²”ìœ„ë¡œ
                range_index += 1
                page_index = 1
                continue
            else:
                break
            
        if page_index > MAX_PAGES_PER_RANGE:
            if not use_bgn_end:
                print(f"   âš ï¸ {range_name}: {page_index-1}í˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘")
                range_index += 1
                page_index = 1
                continue
            else:
                print(f"âš ï¸ ì•ˆì „ì¥ì¹˜: {page_index-1}í˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘ ì™„ë£Œ")
                break
    
    print(f"âœ… [{facility_type}] {method_name}: ì´ {len(all_data)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
    return all_data

def filter_by_opening_date(data: List, start_date: str, end_date: str, facility_type: str) -> List[Dict]:
    """ê°œì›ì¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° í•„í„°ë§"""
    filtered_facilities = []
    
    for row in data:
        apv_perm_ymd = row.find('apvPermYmd')
        if apv_perm_ymd is not None and apv_perm_ymd.text:
            opening_date = apv_perm_ymd.text.strip()
            
            # ë‚ ì§œ í˜•ì‹ í†µì¼ (í•˜ì´í”ˆ ì œê±°)
            normalized_opening_date = opening_date.replace('-', '')
            
            if start_date <= normalized_opening_date <= end_date:
                facility = extract_facility_info(row)
                facility['ì‹œì„¤ìœ í˜•'] = facility_type
                facility['ë°ì´í„°ì†ŒìŠ¤'] = ''  # ë‚˜ì¤‘ì— ì„¤ì •ë¨
                filtered_facilities.append(facility)
    
    return filtered_facilities

def extract_facility_info(row) -> Dict:
    """XML í–‰ì—ì„œ ì˜ë£Œê¸°ê´€ ì •ë³´ ì¶”ì¶œ"""
    def get_text(element_name):
        element = row.find(element_name)
        return element.text.strip() if element is not None and element.text else None
    
    return {
        "ì‚¬ì—…ì¥ëª…": get_text('bplcNm'),
        "ê°œì›ì¼": get_text('apvPermYmd'),
        "ì£¼ì†Œ": get_text('rdnWhlAddr'),
        "ì—…íƒœêµ¬ë¶„": get_text('uptaeNm'),
        "ì „í™”ë²ˆí˜¸": get_text('siteTel'),
        "ê´€ë¦¬ë²ˆí˜¸": get_text('mgtNo')
    }

# ============================================================
# í†µí•© ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
# ============================================================

def collect_all_facilities(api_start: str, api_end: str) -> Dict[str, List[Dict]]:
    """ëª¨ë“  ìœ í˜•ì˜ ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘"""
    all_facilities_by_type = {}
    
    for facility_type, service_id in SERVICE_IDS.items():
        print(f"\n{'='*60}")
        print(f"ğŸ¥ {facility_type} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print(f"{'='*60}")
        
        # 1ë‹¨ê³„: bgnYmd/endYmd ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        bgn_end_data = fetch_medical_data_comprehensive(
            api_start, api_end, service_id, facility_type, use_bgn_end=True
        )
        bgn_end_facilities = filter_by_opening_date(bgn_end_data, api_start, api_end, facility_type)
        
        print(f"\nğŸ” [{facility_type}] bgnYmd/endYmdì—ì„œ {len(bgn_end_facilities)}ê°œ ë°œê²¬")
        
        # 2ë‹¨ê³„: lastModTsBgn/lastModTsEnd ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        lastmod_data = fetch_medical_data_comprehensive(
            api_start, api_end, service_id, facility_type, use_bgn_end=False
        )
        lastmod_facilities = filter_by_opening_date(lastmod_data, api_start, api_end, facility_type)
        
        print(f"ğŸ” [{facility_type}] lastModTsBgn/lastModTsEndì—ì„œ {len(lastmod_facilities)}ê°œ ë°œê²¬")
        
        # 3ë‹¨ê³„: ì¤‘ë³µ ì œê±° ë° ë°ì´í„° í†µí•©
        all_facilities = {}
        
        # bgnYmd/endYmd ë°ì´í„° ì¶”ê°€
        for facility in bgn_end_facilities:
            mgt_no = facility['ê´€ë¦¬ë²ˆí˜¸']
            if mgt_no:
                facility['ë°ì´í„°ì†ŒìŠ¤'] = 'bgnYmd/endYmd'
                all_facilities[mgt_no] = facility
        
        # lastModTsBgn/lastModTsEnd ë°ì´í„° ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
        duplicates = 0
        for facility in lastmod_facilities:
            mgt_no = facility['ê´€ë¦¬ë²ˆí˜¸']
            if mgt_no:
                if mgt_no not in all_facilities:
                    facility['ë°ì´í„°ì†ŒìŠ¤'] = 'lastModTsBgn/lastModTsEnd'
                    all_facilities[mgt_no] = facility
                else:
                    duplicates += 1
        
        final_facilities = list(all_facilities.values())
        
        print(f"ğŸ”„ [{facility_type}] ì¤‘ë³µ ì œê±°ëœ í•­ëª©: {duplicates}ê°œ")
        print(f"âœ… [{facility_type}] ìµœì¢… ê²°ê³¼: {len(final_facilities)}ê°œ")
        
        all_facilities_by_type[facility_type] = final_facilities
    
    return all_facilities_by_type

# ============================================================
# ì¶œë ¥ ë° ì €ì¥ í•¨ìˆ˜ë“¤
# ============================================================

def print_integrated_report(facilities_by_type: Dict[str, List[Dict]], 
                          display_start: str, display_end: str, 
                          save_file: Optional[str] = None):
    """í†µí•© ë¦¬í¬íŠ¸ ì¶œë ¥"""
    
    # ì „ì²´ í†µí•© ë°ì´í„° ìƒì„±
    all_facilities = []
    for facility_type, facilities in facilities_by_type.items():
        all_facilities.extend(facilities)
    
    # ê°œì›ì¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    all_facilities.sort(key=lambda x: x['ê°œì›ì¼'] or '')
    
    # í—¤ë” ì¶œë ¥
    print("\n" + "="*100)
    print(f"ğŸ¥ í†µí•© ì˜ë£Œê¸°ê´€ ê°œì› ë¦¬í¬íŠ¸")
    print(f"ğŸ“… ê¸°ê°„: {display_start} ~ {display_end}")
    print(f"ğŸ¯ ì´ {len(all_facilities)}ê°œ ì˜ë£Œê¸°ê´€ ê°œì›")
    for facility_type, facilities in facilities_by_type.items():
        print(f"   - {facility_type}: {len(facilities)}ê°œ")
    print("="*100)
    
    if not all_facilities:
        print("ğŸ“­ í•´ë‹¹ ê¸°ê°„ì— ê°œì›í•œ ì˜ë£Œê¸°ê´€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
    table_data = []
    for facility in all_facilities:
        # ë‚ ì§œ í˜•ì‹ í†µì¼ (YYYY-MM-DD)
        opening_date = facility['ê°œì›ì¼']
        if opening_date and '-' not in opening_date:
            opening_date = f"{opening_date[:4]}-{opening_date[4:6]}-{opening_date[6:8]}"
        
        # ì£¼ì†Œ ì „ì²´ í‘œì‹œ
        address = facility['ì£¼ì†Œ'] or '-'
        
        # ì „í™”ë²ˆí˜¸ ì²˜ë¦¬
        phone = facility['ì „í™”ë²ˆí˜¸'] or '-'
        
        table_data.append([
            facility['ì‹œì„¤ìœ í˜•'],                 # ì‹œì„¤ìœ í˜•
            facility['ì—…íƒœêµ¬ë¶„'] or '-',          # êµ¬ë¶„
            facility['ì‚¬ì—…ì¥ëª…'] or '-',          # ì‚¬ì—…ìëª…
            address,                             # ì£¼ì†Œ
            phone,                              # ì „í™”ë²ˆí˜¸
            opening_date or '-'                 # ì¸í—ˆê°€ì¼
        ])
    
    # í…Œì´ë¸” í—¤ë”
    headers = ["ì‹œì„¤ìœ í˜•", "êµ¬ë¶„", "ì‚¬ì—…ìëª…", "ì£¼ì†Œ", "ì „í™”ë²ˆí˜¸", "ì¸í—ˆê°€ì¼"]
    
    # êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ìš© CSV í˜•ì‹
    print("\nğŸ“Š êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ìš© ë³µì‚¬ í˜•ì‹")
    print("-" * 120)
    print("â–¼ ì•„ë˜ í…Œì´ë¸”ì„ ë“œë˜ê·¸í•˜ì—¬ êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ë³µì‚¬ ë¶™ì—¬ë„£ê¸° í•˜ì„¸ìš”")
    print()
    
    # CSV í—¤ë” ì¶œë ¥
    csv_headers = [f'"{header}"' for header in headers]
    print(",".join(csv_headers))
    
    # CSV ë°ì´í„° ì¶œë ¥
    for row in table_data:
        cleaned_row = [str(cell).replace('\n', ' ').replace('\r', ' ').replace('"', '""').strip() for cell in row]
        csv_row = [f'"{cell}"' for cell in cleaned_row]
        print(",".join(csv_row))
    
    print()
    print("â–² ìœ„ í‘œë¥¼ ë“œë˜ê·¸í•˜ì—¬ ë³µì‚¬í•˜ì„¸ìš” (êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ìš©)")
    
    # ìœ í˜•ë³„ ìƒì„¸ ë¦¬ìŠ¤íŠ¸
    print("\n\nğŸ“‹ ìœ í˜•ë³„ ìƒì„¸ ë¦¬ìŠ¤íŠ¸")
    print("="*100)
    
    for facility_type, facilities in facilities_by_type.items():
        if facilities:
            print(f"\nğŸ¥ {facility_type} ({len(facilities)}ê°œ)")
            print("-" * 80)
            
            # ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
            sorted_facilities = sorted(facilities, key=lambda x: x['ê°œì›ì¼'] or '')
            
            for i, facility in enumerate(sorted_facilities, 1):
                opening_date = facility['ê°œì›ì¼']
                if opening_date and '-' not in opening_date:
                    opening_date = f"{opening_date[:4]}-{opening_date[4:6]}-{opening_date[6:8]}"
                
                print(f"{i}. {facility['ì‚¬ì—…ì¥ëª…']}")
                print(f"   ğŸ“‹ {facility['ì—…íƒœêµ¬ë¶„'] or 'ë¶„ë¥˜ì—†ìŒ'}")
                print(f"   ğŸ“… {opening_date}")
                print(f"   ğŸ“ {facility['ì£¼ì†Œ'] or 'ì£¼ì†Œì—†ìŒ'}")
                print(f"   ğŸ“ {facility['ì „í™”ë²ˆí˜¸'] or 'ì „í™”ë²ˆí˜¸ì—†ìŒ'}")
                print()
    
    # í†µê³„ ì •ë³´
    print("\nğŸ“Š í†µí•© í†µê³„ ì •ë³´")
    print("="*100)
    
    # ë‚ ì§œë³„ ë¶„í¬
    by_date = {}
    for facility in all_facilities:
        date = facility['ê°œì›ì¼']
        if date:
            if '-' in date:
                formatted_date = date
            else:
                formatted_date = f"{date[:4]}-{date[4:6]}-{date[6:8]}"
            
            if formatted_date not in by_date:
                by_date[formatted_date] = {'ì´ê³„': 0}
            by_date[formatted_date]['ì´ê³„'] += 1
            
            # ìœ í˜•ë³„ ì¹´ìš´íŠ¸
            facility_type = facility['ì‹œì„¤ìœ í˜•']
            if facility_type not in by_date[formatted_date]:
                by_date[formatted_date][facility_type] = 0
            by_date[formatted_date][facility_type] += 1
    
    print(f"\nğŸ“… ë‚ ì§œë³„ ë¶„í¬:")
    date_headers = ["ë‚ ì§œ", "ì´ê³„"] + list(SERVICE_IDS.keys())
    date_table = []
    for date in sorted(by_date.keys()):
        row = [date, f"{by_date[date]['ì´ê³„']}ê°œ"]
        for facility_type in SERVICE_IDS.keys():
            count = by_date[date].get(facility_type, 0)
            row.append(f"{count}ê°œ" if count > 0 else "-")
        date_table.append(row)
    
    print(tabulate(date_table, headers=date_headers, tablefmt="simple"))
    
    # ì§€ì—­ë³„ ë¶„í¬
    regions = {}
    for facility in all_facilities:
        if facility['ì£¼ì†Œ']:
            region = facility['ì£¼ì†Œ'].split()[0]
            if region not in regions:
                regions[region] = {'ì´ê³„': 0}
            regions[region]['ì´ê³„'] += 1
            
            # ìœ í˜•ë³„ ì¹´ìš´íŠ¸
            facility_type = facility['ì‹œì„¤ìœ í˜•']
            if facility_type not in regions[region]:
                regions[region][facility_type] = 0
            regions[region][facility_type] += 1
    
    if regions:
        print(f"\nğŸ—ºï¸ ì§€ì—­ë³„ ë¶„í¬:")
        region_headers = ["ì§€ì—­", "ì´ê³„"] + list(SERVICE_IDS.keys())
        region_table = []
        for region in sorted(regions.keys()):
            row = [region, f"{regions[region]['ì´ê³„']}ê°œ"]
            for facility_type in SERVICE_IDS.keys():
                count = regions[region].get(facility_type, 0)
                row.append(f"{count}ê°œ" if count > 0 else "-")
            region_table.append(row)
        
        print(tabulate(region_table, headers=region_headers, tablefmt="simple"))
    
    # íŒŒì¼ ì €ì¥
    if save_file:
        save_integrated_data(facilities_by_type, save_file, display_start, display_end)

def save_integrated_data(facilities_by_type: Dict[str, List[Dict]], 
                        filename: str, start_date: str, end_date: str):
    """í†µí•© ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    # ì „ì²´ ë°ì´í„° í†µí•©
    all_facilities = []
    for facilities in facilities_by_type.values():
        all_facilities.extend(facilities)
    
    report_data = {
        "report_info": {
            "title": "í†µí•© ì˜ë£Œê¸°ê´€ ê°œì› ë¦¬í¬íŠ¸",
            "period": f"{start_date} ~ {end_date}",
            "total_count": len(all_facilities),
            "count_by_type": {
                facility_type: len(facilities) 
                for facility_type, facilities in facilities_by_type.items()
            },
            "generated_at": datetime.now().isoformat()
        },
        "facilities_by_type": facilities_by_type,
        "all_facilities": all_facilities
    }
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ë°ì´í„°ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

# ============================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="í†µí•© ì˜ë£Œê¸°ê´€ ë°ì´í„° ì¶”ì¶œê¸°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  %(prog)s                                # í•˜ë“œì½”ë”© ëª¨ë“œ (íŒŒì¼ ìƒë‹¨ HARDCODED_START_DATE/END_DATE ì‚¬ìš©)
  %(prog)s --week 2025-06-15              # 2025-06-15ê°€ í¬í•¨ëœ ì£¼ì˜ ë°ì´í„°
  %(prog)s --current-week                 # í˜„ì¬ ì£¼ì˜ ë°ì´í„°
  %(prog)s --start-date 2025-06-08 --days 5  # 2025-06-08ë¶€í„° 5ì¼ê°„
  %(prog)s --week 2025-06-15 --save integrated_report.json  # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
  
í•˜ë“œì½”ë”© ëª¨ë“œ ì‚¬ìš©ë²•:
  1. íŒŒì¼ ìƒë‹¨ì˜ HARDCODED_START_DATE, HARDCODED_END_DATE ìˆ˜ì •
  2. python %(prog)s ì‹¤í–‰ (ì¸ì ì—†ì´)
        """
    )
    
    # ë‚ ì§œ ì˜µì…˜ ê·¸ë£¹
    date_group = parser.add_mutually_exclusive_group(required=not ENABLE_HARDCODED_MODE)
    date_group.add_argument('--week', type=str, metavar='YYYY-MM-DD',
                           help='í•´ë‹¹ ë‚ ì§œê°€ í¬í•¨ëœ ì£¼ì˜ ì›”ìš”ì¼ë¶€í„° ë°ì´í„° ì¶”ì¶œ')
    date_group.add_argument('--current-week', action='store_true',
                           help='í˜„ì¬ ì£¼ì˜ ë°ì´í„° ì¶”ì¶œ')
    date_group.add_argument('--start-date', type=str, metavar='YYYY-MM-DD',
                           help='ì‹œì‘ ë‚ ì§œ ì§ì ‘ ì§€ì •')
    
    # ê¸°íƒ€ ì˜µì…˜
    parser.add_argument('--days', type=int, default=DEFAULT_DAYS,
                       help=f'ì¶”ì¶œ ê¸°ê°„ (ì¼ìˆ˜, ê¸°ë³¸ê°’: {DEFAULT_DAYS})')
    parser.add_argument('--save', type=str, metavar='FILENAME',
                       help='ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥')
    
    args = parser.parse_args()
    
    # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
    try:
        # í•˜ë“œì½”ë”© ëª¨ë“œ í™•ì¸
        if ENABLE_HARDCODED_MODE and not any([args.current_week, args.week, args.start_date]):
            # í•˜ë“œì½”ë”© ê°’ ì‚¬ìš©
            print(f"ğŸ”§ í•˜ë“œì½”ë”© ëª¨ë“œ: {HARDCODED_START_DATE} ~ {HARDCODED_END_DATE}")
            api_start = HARDCODED_START_DATE
            api_end = HARDCODED_END_DATE
            
            # í‘œì‹œìš© ë‚ ì§œ í˜•ì‹ ë³€í™˜
            start_dt = datetime.strptime(api_start, "%Y%m%d")
            end_dt = datetime.strptime(api_end, "%Y%m%d")
            display_start = format_date_for_display(start_dt)
            display_end = format_date_for_display(end_dt)
            
        elif args.current_week:
            start_date = get_current_week_start()
            api_start, api_end, display_start, display_end = calculate_date_range(start_date, args.days)
        elif args.week:
            start_date = get_week_start_date(args.week)
            api_start, api_end, display_start, display_end = calculate_date_range(start_date, args.days)
        else:  # args.start_date
            start_date = datetime.strptime(args.start_date, "%Y-%m-%d")
            api_start, api_end, display_start, display_end = calculate_date_range(start_date, args.days)
        
    except ValueError as e:
        print(f"âŒ ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {e}")
        print("ì˜¬ë°”ë¥¸ í˜•ì‹: YYYY-MM-DD (ì˜ˆ: 2025-06-15)")
        return
    
    print(f"ğŸ¯ ëª©í‘œ: ê°œì›ì¼ {api_start}~{api_end}ì¸ ëª¨ë“  ì˜ë£Œê¸°ê´€ ì¶”ì¶œ")
    print(f"ğŸ“Š ë³‘ì›, ì˜ì›, ì•½êµ­ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
    
    # ëª¨ë“  ì˜ë£Œê¸°ê´€ ë°ì´í„° ìˆ˜ì§‘
    facilities_by_type = collect_all_facilities(api_start, api_end)
    
    # í†µí•© ë¦¬í¬íŠ¸ ì¶œë ¥
    print_integrated_report(facilities_by_type, display_start, display_end, args.save)

if __name__ == "__main__":
    main() 